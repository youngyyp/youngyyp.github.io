<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/Iron-Man-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/Iron-Man-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"youngyyp.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="UAV Geolocalization Using Satellite Imagery Motivation 无人机通常靠GPS来获得全局姿态估计，然而为了使用GPS进行精确的地理定位，无人机必须能够从四个或更多的GPS卫星接收直接的视线。这可能是一个问题，如果存在高楼大厦，山脉或干扰器，可以阻碍来自卫星的信号。 那么我们能在没有GPS的情况下推断出无人机的全局姿态吗? 答案是肯定的，我们可以使用">
<meta property="og:type" content="article">
<meta property="og:title" content="UAV和卫星图像配准论文阅读">
<meta property="og:url" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/index.html">
<meta property="og:site_name" content="young&#39;s blog">
<meta property="og:description" content="UAV Geolocalization Using Satellite Imagery Motivation 无人机通常靠GPS来获得全局姿态估计，然而为了使用GPS进行精确的地理定位，无人机必须能够从四个或更多的GPS卫星接收直接的视线。这可能是一个问题，如果存在高楼大厦，山脉或干扰器，可以阻碍来自卫星的信号。 那么我们能在没有GPS的情况下推断出无人机的全局姿态吗? 答案是肯定的，我们可以使用">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221031184827896.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221031194705659.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221102151027518.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221101105655053.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221101110400421.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221108091237749.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221108110109358.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221108105026501.png">
<meta property="og:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221106211924306.png">
<meta property="article:published_time" content="2022-11-08T01:49:41.000Z">
<meta property="article:modified_time" content="2023-03-11T06:21:01.076Z">
<meta property="article:author" content="young">
<meta property="article:tag" content="图像匹配">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221031184827896.png">

<link rel="canonical" href="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>UAV和卫星图像配准论文阅读 | young's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="young's blog" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">young's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">慢慢来，比较快</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">30</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://raw.githubusercontent.com/youngyyp/blogpicture/master/img/image-20210212125129052.png">
      <meta itemprop="name" content="young">
      <meta itemprop="description" content="你的征途当是星辰大海">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="young's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          UAV和卫星图像配准论文阅读
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-11-08 09:49:41" itemprop="dateCreated datePublished" datetime="2022-11-08T09:49:41+08:00">2022-11-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-11 14:21:01" itemprop="dateModified" datetime="2023-03-11T14:21:01+08:00">2023-03-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="UAV-Geolocalization-Using-Satellite-Imagery"><a href="#UAV-Geolocalization-Using-Satellite-Imagery" class="headerlink" title="UAV Geolocalization Using Satellite Imagery"></a><a target="_blank" rel="noopener" href="https://abhinavtripathi95.github.io/lets-talk/technical/2020/08/03/uav-geolocalization.html">UAV Geolocalization Using Satellite Imagery</a></h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>无人机通常靠GPS来获得全局姿态估计，然而为了使用GPS进行精确的地理定位，无人机必须能够从四个或更多的GPS卫星接收直接的视线。这可能是一个问题，如果存在高楼大厦，山脉或干扰器，可以阻碍来自卫星的信号。<br>那么我们能在没有GPS的情况下推断出无人机的全局姿态吗?<br>答案是肯定的，我们可以使用无人机下面附加的相机传感器来比较场景和卫星图像，并推断出无人机的位置。</p>
<h3 id="Geolocalization-as-an-Image-Matching-Problem"><a href="#Geolocalization-as-an-Image-Matching-Problem" class="headerlink" title="Geolocalization as an Image Matching Problem"></a>Geolocalization as an Image Matching Problem</h3><p>考虑这样一个场景，您有一个卫星图像数据库，其中标注了它们的位置。<br>通过将无人机相机的图像与数据库进行精确匹配，可以很好地获得无人机的经纬度近似。<br>为了从卫星数据库中检索相似的图像，我们必须能够精确地匹配卫星图像与无人机相机馈送。<br>因此，在本研究中，我们将自己局限于<strong>航空图像匹配问题</strong>，训练一个深度学习模型，<strong>可以精确匹配来自卫星和无人机相机的图像</strong>。</p>
<h2 id="UAV-Pose-Estimation-using-Cross-view-Geolocalization-with-Satellite-Imagery-ICRA-2019"><a href="#UAV-Pose-Estimation-using-Cross-view-Geolocalization-with-Satellite-Imagery-ICRA-2019" class="headerlink" title="UAV Pose Estimation using Cross-view Geolocalization with Satellite Imagery (ICRA 2019)"></a>UAV Pose Estimation using Cross-view Geolocalization with Satellite Imagery (ICRA 2019)</h2><p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221031184827896.png" alt="image-20221031184827896" style="zoom:30%;"></p>
<p>数据集是从谷歌地图上收集的“Sample matching pairs of UAV images from Google Earth (top row) and satellite images from Google Maps (bottom row).”</p>
<p>scene localization network 用于对每张图片生成一个描述符，计算欧式距离d，用于计算权重</p>
<p>Camera Localization network 是一个双分支网络，第一个分支输出一个热力图，最大值位置代表x,y水平位置，第二个分支直接回归垂直位置，朝向(heading)和倾斜角度(tilt)</p>
<p>Cross-view Geolocalization 模块，将多张图像经过两个网络后的结果根据d计算加权，生成最终相机位姿</p>
<h2 id="Visual-Localization-with-Google-Earth-Images-for-Robust-Global-Pose-Estimation-of-UAVs（ICRA-2020）"><a href="#Visual-Localization-with-Google-Earth-Images-for-Robust-Global-Pose-Estimation-of-UAVs（ICRA-2020）" class="headerlink" title="Visual Localization with Google Earth Images for Robust Global Pose Estimation of UAVs（ICRA 2020）"></a>Visual Localization with Google Earth Images for Robust Global Pose Estimation of UAVs（ICRA 2020）</h2><p>数据集：<a target="_blank" rel="noopener" href="https://www.dynsyslab.org/cloud-dataset/">CLOUD: Canadian Longterm Outdoor UAV Dataset | Dynamic Systems Lab | Prof. Angela Schoellig (dynsyslab.org)</a></p>
<p>包含季节变化和光照变化的无人机图像，以及UAV的GPS位置信息和姿态信息</p>
<p>还包括对应的卫星图像（由谷歌地球生成）</p>
<p>在这项工作中，所有真实的和渲染的图像都是用指向最低点的相机拍摄的</p>
<h2 id="UAV-Localization-Using-Autoencoded-Satellite-Images（IEEE-ROBOTICS-AND-AUTOMATION-LETTERS-2021）"><a href="#UAV-Localization-Using-Autoencoded-Satellite-Images（IEEE-ROBOTICS-AND-AUTOMATION-LETTERS-2021）" class="headerlink" title="UAV Localization Using Autoencoded Satellite Images（IEEE ROBOTICS AND AUTOMATION LETTERS 2021）"></a>UAV Localization Using Autoencoded Satellite Images（IEEE ROBOTICS AND AUTOMATION LETTERS 2021）</h2><p>和上一篇是一个团队</p>
<p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221031194705659.png" alt="image-20221031194705659" style="zoom:33%;"></p>
<h3 id="动机："><a href="#动机：" class="headerlink" title="动机："></a>动机：</h3><p>由于谷歌地图中用于重建的卫星图像是多年前拍摄的，在照明、小对象移动(例如车辆、拖车)、大的结构变化(例如建筑物的增建/拆除)以及不寻常的对象重建方面与现场图像有所不同，特别是对于树木等非矩形对象。这使得<strong>基于特征的方法在很多情况下很难获得准确和稳健的结果。</strong></p>
<h3 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h3><p>图像在GE中围绕所需的飞行路线进行渲染。对这些特定于路径的图像进行自动编码器训练，以将它们压缩成小得多的矢量表示。同样的自动编码器也用于压缩实时图像。通过内积核将压缩的实时图像向量与附近的所有压缩GE图像向量进行比较。这会产生与每个相应GE图像姿势相关联的权重。<br>根据这些权重，计算出带有伴随协方差的经度、纬度和航向的位置。</p>
<h3 id="数据集："><a href="#数据集：" class="headerlink" title="数据集："></a>数据集：</h3><p>uav图像+GE图像</p>
<p>一天中六个不同时刻的1.1公里路径上的真实无人机图像数据集上进行了演示，覆盖了几种照明条件</p>
<h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><p>查找速度快</p>
<h3 id="缺陷："><a href="#缺陷：" class="headerlink" title="缺陷："></a>缺陷：</h3><p>不是端到端训练</p>
<h3 id="改进："><a href="#改进：" class="headerlink" title="改进："></a>改进：</h3><p>用最新的基于特征的方法进行尝试</p>
<h2 id="UAV-Satellite-View-Synthesis-for-Cross-view-Geo-Localization"><a href="#UAV-Satellite-View-Synthesis-for-Cross-view-Geo-Localization" class="headerlink" title="UAV-Satellite View Synthesis for Cross-view Geo-Localization"></a>UAV-Satellite View Synthesis for Cross-view Geo-Localization</h2><p>（IEEE Transactions on Circuits and Systems for Video Technology TCSVT 2021)</p>
<h3 id="数据集：-1"><a href="#数据集：-1" class="headerlink" title="数据集："></a>数据集：</h3><p>本研究使用的数据集是大学1652[30]，其中包含来自全球72所大学的1652栋建筑（1652个地点）。据我们所知，这是迄今为止<strong>唯一一个同时包含无人机视图图像和卫星视图图像的数据集</strong>。每个建筑物都与三个不同视角的图像相关联（见图7），包括一个卫星视图图像、54个不同高度和角度的无人机视图图像以及一个或多个地面视图图像。在本文中，我们使用了卫星图像（垂直视图）和无人机图像（斜视图）。大多数无人机视图是倾斜的，这为使用透视投影变换实现更好的匹配性能提供了巨大的潜力。</p>
<h3 id="方法：-1"><a href="#方法：-1" class="headerlink" title="方法："></a>方法：</h3><p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221102151027518.png" alt="image-20221102151027518" style="zoom:33%;"></p>
<p>通过数据集的先验信息进行的透视投影变换（？？？），然后采用GAN网络生成和卫星图像风格相似的图像（同时视角也更相似），如下图所示</p>
<p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221101105655053.png" alt="image-20221101105655053" style="zoom: 80%;"></p>
<p>随后对特征图采用一个方环分割策略来获取距离图像中心不同距离的上下文特征信息</p>
<pre><code>如图6所示，我们将高级特征分为正方形环形分区中的几个部分。由于地理目标通常位于图像的中心，周围有上下文信息，分割方法不仅可以获得地理目标信息（区域A和B），还可以获得与地理目标具有不同距离的若干上下文信息部分（区域C和D）。因此，我们可以显式地利用上下文信息来优化PCL。我们观察到，我们的分割策略在本质上对图像旋转是鲁棒的。例如，当将图6中中间行的图像旋转到顶行的图像时，四个区域（A、B、C和D）仍然包含与中间图像的对应区域相同的信息。因此，根据方环分割策略设计的网络对图像旋转具有良好的鲁棒性
</code></pre><p>(缺陷：只对90°旋转鲁棒，且目标不一定位于图像中心)</p>
<p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221101110400421.png" alt="image-20221101110400421" style="zoom:33%;"></p>
<p>最后对图片生成一个描述符，并比较和其他图像的余弦相似性</p>
<h3 id="疑问："><a href="#疑问：" class="headerlink" title="疑问："></a>疑问：</h3><p>UAV图像和卫星图像的视野范围基本一样？</p>
<p>是否能生成已知对应关系的GAN网络</p>
<h2 id="University-1652-A-Multi-view-Multi-source-Benchmark-for-Drone-based-Geo-localization"><a href="#University-1652-A-Multi-view-Multi-source-Benchmark-for-Drone-based-Geo-localization" class="headerlink" title="University-1652: A Multi-view Multi-source Benchmark for Drone-based Geo-localization"></a>University-1652: A Multi-view Multi-source Benchmark for Drone-based Geo-localization</h2><p>（ACM Multimedia 2020）</p>
<p>针对跨视角地理定位问题，提出一个baseline和dataset</p>
<p>数据集包含三种视角（地面、无人机、卫星）</p>
<p>Google Earth中的3D引擎用于模拟相机的不同视点。</p>
<h2 id="Joint-Representation-Learning-and-Keypoint-Detection-for-Cross-View-Geo-Localization"><a href="#Joint-Representation-Learning-and-Keypoint-Detection-for-Cross-View-Geo-Localization" class="headerlink" title="Joint Representation Learning and Keypoint Detection for Cross-View Geo-Localization"></a>Joint Representation Learning and Keypoint Detection for Cross-View Geo-Localization</h2><p>(IEEE TRANSACTIONS ON IMAGE PROCESSING 2022)</p>
<p>我们的模型自动从卫星视图图像和无人机视图图像的相应区域提取关键点，而无需额外监督</p>
<p>USAM提取的关键点仅用于增强图像的特征识别，而不是检测实际映射。</p>
<p>（1）我们的方法不需要额外的注释，例如相机姿势、深度等。</p>
<p>（2） 我们的方法不进行方位估计。</p>
<p>（3） 所提出的方法考虑了点对点关系</p>
<p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221108091237749.png" alt="image-20221108091237749"></p>
<p>USC相当于算子</p>
<p>-1 -1 -1</p>
<p>-1  8 -1</p>
<p>-1 -1 -1</p>
<p><a target="_blank" rel="noopener" href="https://github.com/AggMan96/RK-Net">AggMan96/RK-Net: Code for RK-Net (github.com)</a></p>
<h2 id="Real-time-Geo-localization-Using-Satellite-Imagery-and-Topography-for-Unmanned-Aerial-Vehicles"><a href="#Real-time-Geo-localization-Using-Satellite-Imagery-and-Topography-for-Unmanned-Aerial-Vehicles" class="headerlink" title="Real-time Geo-localization Using Satellite Imagery and Topography for Unmanned Aerial Vehicles"></a>Real-time Geo-localization Using Satellite Imagery and Topography for Unmanned Aerial Vehicles</h2><p>使用谷歌地球提供的3D模型+blender渲染卫星图像和深度图像</p>
<p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221108110109358.png" alt="image-20221108110109358" style="zoom: 50%;"></p>
<h2 id="Multiple-environment-Self-adaptive-Network-for-Aerial-view-Geo-localization"><a href="#Multiple-environment-Self-adaptive-Network-for-Aerial-view-Geo-localization" class="headerlink" title="Multiple-environment Self-adaptive Network for Aerial-view Geo-localization"></a>Multiple-environment Self-adaptive Network for Aerial-view Geo-localization</h2><p>(arXiv 2022.4.18)</p>
<p>现有的方法在真实的天气（如雨天和雾天）下会遇到较大的性能下降，因为它们没有考虑训练数据和多个测试环境之间的域转换。为了缩小这一领域差距，我们提出了一种多环境自适应网络（MuSe-Net），以动态调整环境变化引起的领域偏移。<br>特别是，MuSe-Net采用了包含一个多环境类型提取网络和一个自适应特征提取网络的两分支神经网络。顾名思义，多环境风格提取网络用于提取与环境相关的风格信息，而自适应特征提取网络利用自适应调制模块来动态地最小化与环境有关的风格差距。</p>
<p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221108105026501.png" alt="image-20221108105026501"></p>
<h2 id="CMU-amp-ICRA22-UAV俯瞰视觉定位竞赛"><a href="#CMU-amp-ICRA22-UAV俯瞰视觉定位竞赛" class="headerlink" title="CMU&amp;ICRA22 UAV俯瞰视觉定位竞赛"></a>CMU&amp;ICRA22 UAV俯瞰视觉定位竞赛</h2><p>[ICRA2022] General Place Recognition: Visual Terrain Relative Navigation</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1NG411G78L/?spm_id_from=333.337.search-card.all.click&amp;vd_source=0bb4d13f4bd26eaf7f64c37f29dc9f27">CMU &amp; ICRA22 UAV俯瞰视觉定位竞赛冠军技术方案分享|军事科学院_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.sohu.com/a/587059840_121124366">CMU&amp;ICRA22 UAV俯瞰视觉定位竞赛亚军技术方案分享_VINS-Mono_VINS-Fusion_cvlife (sohu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://sites.google.com/andrew.cmu.edu/gpr-competition/">竞赛官网GPR-Competition (google.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/MetaSLAM/ALTO">数据集：MetaSLAM/ALTO: ALTO (Aerial-view Large-scale Terrain-Oriented) dataset (github.com)</a></p>
<h3 id="数据集简介："><a href="#数据集简介：" class="headerlink" title="数据集简介："></a>数据集简介：</h3><p><a target="_blank" rel="noopener" href="https://www.dropbox.com/sh/q1w5dmghbkut553/AAASkcJEpfsV9PbdLjszzdYAa/UAV?dl=0&amp;preview=readme.txt&amp;subfolder_nav_tracking=1">自述文件.txt (dropbox.com)</a></p>
<ul>
<li><p>俄亥俄州到匹兹堡的150公里长的飞行轨迹，使用直升飞机拍摄；</p>
</li>
<li><p>轨迹上包括几种不同难度的环境，包括城市/郊区、森林、农村和其他自然地形。</p>
</li>
<li>测试集中有几年前的图像（2017年同样是飞机拍的），同时也包括2012年的卫星图像</li>
<li>500*500像素</li>
<li>每张直升机图像有成对的卫星图像</li>
<li>包括GPS（全局的位置，亚米级精度, UTM坐标系）和IMU（四元数，相机相对于ECEF参考帧的方向）信息</li>
</ul>
<pre><code>This dataset contains nadir-facing RGB camera imagery captured via commercial helicopter (query), as well
as by high-altitude plane (reference, captured by USGS). We include some query telemetry information that
may be useful for preprocessing or incorporated into your algorithm as contextual information.
We provide three data splits: Train, Val, and Test. These are non-overlapping and include (24701), (3979), 
and (4209) images, respectively. These are all part of a 150km helicopter flight over a variety of
different terrains, including Urban, Suburban, Rural, Dense Forest, Rivers, and Lakes.
For ease of use with deep learning pipelines, we include the images in png format. All images are RGB
and in 500x500 pixel resolution.

In addition to the imagery in the Train and Val sets, we also provide a few csv files.  Their contents are as follows:
    - gt_matches.csv: This file provides the ground truth best match between the query images and the reference images.
        As states above, multiple query images may map to a single reference image. We determine "best match" by using the L2 
        distance of the UTM coordinates associated with the respective images.
        - query_ind: The index of the query image.
        - query_name: The name of the query image.
        - ref_ind: The index of the reference image that best matches the query image.
        - ref_name: The name of the reference image that best matches the query image.
        - distance: The distance (meters) between the query and best matching reference image.

    - query.csv: Telemetry information about each query image frame.
        - easting: The ground truth Easting coordinate (meters) where the image was taken.
        - northing: The ground truth Northing coordinate (meters) where the image was taken.
        - altitude: The ground truth Altitude (meters) above the WGS84 ellipsoid surface.
        - orient_x, orient_y, orient_z, orient_w: The orientation (scalar last quaternion) of the camera with respect the the ECEF reference frame.
        - name: The name of the query image.

    - reference.csv: Information about each reference image frame. Contains information about all offset reference images as well.
        - easting: The ground truth Easting coordinate (meters) where the image was taken.
        - northing: The ground truth Northing coordinate (meters) where the image was taken.
        - name: The directory and name of the reference image.
</code></pre><h2 id="Deep-learning-based-robust-positioning-for-all-weather-autonomous-driving"><a href="#Deep-learning-based-robust-positioning-for-all-weather-autonomous-driving" class="headerlink" title="Deep learning-based robust positioning for all-weather autonomous driving"></a>Deep learning-based robust positioning for all-weather autonomous driving</h2><p>定位能力负责精确预测AV在地图上的位置。AV的大多数核心组件（如预测和规划）都依赖于精确定位，例如在几厘米以内。尽管AV严重依赖于GPS等天基全球导航卫星系统的信号进行定位，但由于障碍物或反射，无线电信号可能在许多环境中丢失或退化。尤其是，在被高层建筑包围的城市地区，AV运营仍然极具挑战性。此外，GPS仅提供米级定位精度，而没有方位信息，这对AV乘客或周围环境中的乘客来说可能是致命的。</p>
<p>自我运动估计方法应利用摄像机（丰富、密集的视觉信息）、激光雷达（可见范围内的精细粒度）和雷达（对恶劣天气的免疫力）的优势，同时解决其相对缺点。</p>
<p>通过重建的质量来创建监督信号</p>
<p>自监督的核心思想<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43882112/article/details/108610832">(54条消息) 【SLAM系列】Unsupervised Learning of Depth and Ego-Motion from Video<em>^</em>^ 晅菲的博客-CSDN博客</a></p>
<p><img src="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&amp;Satellite/%E8%B0%83%E7%A0%94/image-20221106211924306.png" alt="image-20221106211924306"></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>young
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://youngyyp.github.io/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/" title="UAV和卫星图像配准论文阅读">https://youngyyp.github.io/2022/11/08/计算机视觉/UAV&Satellite/调研/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/" rel="tag"><i class="fa fa-tag"></i> 图像匹配</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E5%BC%80%E9%A2%98%E7%9B%B8%E5%85%B3/" rel="prev" title="UAV和卫星图像配准思路">
      <i class="fa fa-chevron-left"></i> UAV和卫星图像配准思路
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/" rel="next" title="pytorch冻结网络模型">
      pytorch冻结网络模型 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <!--插入访客地图-->
      <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=oY_lgWsBgu9UBtnnlW5wbM7G1cJY_9ZHdsx3MAT2Yao&cl=ffffff&w=a"></script>

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#UAV-Geolocalization-Using-Satellite-Imagery"><span class="nav-number">1.</span> <span class="nav-text">UAV Geolocalization Using Satellite Imagery</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Motivation"><span class="nav-number">1.1.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Geolocalization-as-an-Image-Matching-Problem"><span class="nav-number">1.2.</span> <span class="nav-text">Geolocalization as an Image Matching Problem</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UAV-Pose-Estimation-using-Cross-view-Geolocalization-with-Satellite-Imagery-ICRA-2019"><span class="nav-number">2.</span> <span class="nav-text">UAV Pose Estimation using Cross-view Geolocalization with Satellite Imagery (ICRA 2019)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Visual-Localization-with-Google-Earth-Images-for-Robust-Global-Pose-Estimation-of-UAVs%EF%BC%88ICRA-2020%EF%BC%89"><span class="nav-number">3.</span> <span class="nav-text">Visual Localization with Google Earth Images for Robust Global Pose Estimation of UAVs（ICRA 2020）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UAV-Localization-Using-Autoencoded-Satellite-Images%EF%BC%88IEEE-ROBOTICS-AND-AUTOMATION-LETTERS-2021%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">UAV Localization Using Autoencoded Satellite Images（IEEE ROBOTICS AND AUTOMATION LETTERS 2021）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA%EF%BC%9A"><span class="nav-number">4.1.</span> <span class="nav-text">动机：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="nav-number">4.2.</span> <span class="nav-text">方法：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A"><span class="nav-number">4.3.</span> <span class="nav-text">数据集：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E7%82%B9%EF%BC%9A"><span class="nav-number">4.4.</span> <span class="nav-text">优点：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%BA%E9%99%B7%EF%BC%9A"><span class="nav-number">4.5.</span> <span class="nav-text">缺陷：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%B9%E8%BF%9B%EF%BC%9A"><span class="nav-number">4.6.</span> <span class="nav-text">改进：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UAV-Satellite-View-Synthesis-for-Cross-view-Geo-Localization"><span class="nav-number">5.</span> <span class="nav-text">UAV-Satellite View Synthesis for Cross-view Geo-Localization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A-1"><span class="nav-number">5.1.</span> <span class="nav-text">数据集：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%EF%BC%9A-1"><span class="nav-number">5.2.</span> <span class="nav-text">方法：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%96%91%E9%97%AE%EF%BC%9A"><span class="nav-number">5.3.</span> <span class="nav-text">疑问：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#University-1652-A-Multi-view-Multi-source-Benchmark-for-Drone-based-Geo-localization"><span class="nav-number">6.</span> <span class="nav-text">University-1652: A Multi-view Multi-source Benchmark for Drone-based Geo-localization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Joint-Representation-Learning-and-Keypoint-Detection-for-Cross-View-Geo-Localization"><span class="nav-number">7.</span> <span class="nav-text">Joint Representation Learning and Keypoint Detection for Cross-View Geo-Localization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Real-time-Geo-localization-Using-Satellite-Imagery-and-Topography-for-Unmanned-Aerial-Vehicles"><span class="nav-number">8.</span> <span class="nav-text">Real-time Geo-localization Using Satellite Imagery and Topography for Unmanned Aerial Vehicles</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multiple-environment-Self-adaptive-Network-for-Aerial-view-Geo-localization"><span class="nav-number">9.</span> <span class="nav-text">Multiple-environment Self-adaptive Network for Aerial-view Geo-localization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CMU-amp-ICRA22-UAV%E4%BF%AF%E7%9E%B0%E8%A7%86%E8%A7%89%E5%AE%9A%E4%BD%8D%E7%AB%9E%E8%B5%9B"><span class="nav-number">10.</span> <span class="nav-text">CMU&amp;ICRA22 UAV俯瞰视觉定位竞赛</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B%EF%BC%9A"><span class="nav-number">10.1.</span> <span class="nav-text">数据集简介：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-learning-based-robust-positioning-for-all-weather-autonomous-driving"><span class="nav-number">11.</span> <span class="nav-text">Deep learning-based robust positioning for all-weather autonomous driving</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="young"
      src="https://raw.githubusercontent.com/youngyyp/blogpicture/master/img/image-20210212125129052.png">
  <p class="site-author-name" itemprop="name">young</p>
  <div class="site-description" itemprop="description">你的征途当是星辰大海</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">40</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">young</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

<span id="busuanzi_container_site_uv">
  本站访问次数：<span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
</span>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>
    <script defer src="//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'Xwh80uoDDnqi8uKvWVp8c9rr-gzGzoHsz',
      appKey     : 'I7r0pki5w3TvCpU6LC8I3b2R',
      placeholder: "欢迎大家评论哦~",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-CN' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
