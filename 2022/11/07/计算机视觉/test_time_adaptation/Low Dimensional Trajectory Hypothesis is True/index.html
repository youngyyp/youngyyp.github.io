<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>子空间论文阅读 | young&#39;s blog</title>
  <meta name="keywords" content=" test time adaptation ">
  <meta name="description" content="子空间论文阅读 | young&#39;s blog">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="Oops～，我崩溃了！找不到你想要的页面了">
<meta property="og:type" content="website">
<meta property="og:title" content="404">
<meta property="og:url" content="https://youngyyp.github.io/404.html">
<meta property="og:site_name" content="young&#39;s blog">
<meta property="og:description" content="Oops～，我崩溃了！找不到你想要的页面了">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-02-23T11:37:07.000Z">
<meta property="article:modified_time" content="2021-02-10T02:51:50.601Z">
<meta property="article:author" content="young">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="young's blog" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism.css" type="text/css">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/avatar.jpg"/>
</a>
<div class="author">
    <span>young</span>
</div>

<div class="icon">
    
        
            <a title="rss"
               href="/atom.xml"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-rss"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="github"
               href="https://github.com/yelog"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-github"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="facebook"
               href="https://www.facebook.com/faker.tops"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-facebook"></use>
                    </svg>
                
            </a>
        
    
        
    
        
    
        
            <a title="instagram"
               href="https://www.facebook.com/faker.tops"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-instagram"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="reddit"
               href="https://www.reddit.com/user/yelog/"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-reddit"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="weibo"
               href="http://weibo.com/u/2307534817"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-weibo"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="jianshu"
               href="https://www.jianshu.com/u/ff56736de7cf"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-jianshu"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="zhihu"
               href="https://www.zhihu.com/people/jaytp/activities"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-zhihu"></use>
                    </svg>
                
            </a>
        
    
        
    
        
            <a title="oschina"
               href="https://my.oschina.net/yelog"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-oschina"></use>
                    </svg>
                
            </a>
        
    
        
    
        
            <a title="email"
               href="mailto:jaytp@qq.com"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-email"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="qq"
               href="http://wpa.qq.com/msgrd?v=3&uin=872336115&site=qq&menu=yes"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-qq"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="kugou"
               href="https://www.kugou.com/"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-kugou"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="neteasemusic"
               href="https://music.163.com/#/user/home?id=88151013"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-neteasemusic"></use>
                    </svg>
                
            </a>
        
    
</div>




<ul>
    <li>
        <div class="all active" data-rel="全部文章">全部文章
            
                <small>(40)</small>
            
        </div>
    </li>
    
        
            
                <li>
                    <div data-rel="计算机视觉">
                        
                        计算机视觉
                        <small>(19)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="嵌入式和硬件">
                        
                        嵌入式和硬件
                        <small>(2)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="软件使用">
                        
                        软件使用
                        <small>(3)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="位姿估计">
                        
                        位姿估计
                        <small>(1)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="CPP">
                        
                        CPP
                        <small>(9)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="FPGA">
                        
                        FPGA
                        <small>(6)</small>
                        
                    </div>
                    
                </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
            
            
            
    </div>
    <div>
        
            <a class="about  hasFriend  site_url"
               
               href="/about">关于</a>
        
        <a style="width: 50%"
                
                                           class="friends">友链</a>
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="40">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>目标检测</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>目标识别</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>深度学习</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>神经网络</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>事件相机</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>数电</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>特征匹配</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>图像处理</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>图像匹配</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>位姿估计</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>线路故障检测</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>障碍物识别</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>正交解调，FPGA</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>自平衡电桥</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Atlas</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>batch norm</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>dehazing</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>haze removal</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>hexo指令</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>heze removal</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>HLS</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>modelsim</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>pytorch</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>SLAM</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>test time adaptation</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>ubuntu</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>verilog</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>vivado</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>yolo</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>ZYNQ</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="动态规划">动态规划</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%AD%97%E7%AC%A6%E4%B8%B2/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="字符串">字符串</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E6%95%B0%E7%BB%84/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="数组">数组</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="贪心算法">贪心算法</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E9%93%BE%E8%A1%A8/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="链表">链表</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%9B%9E%E6%BA%AF/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="回溯">回溯</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%93%88%E5%B8%8C%E8%A1%A8/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="哈希表">哈希表</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="栈与队列">栈与队列</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E4%BA%8C%E5%8F%89%E6%A0%91/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="二叉树">二叉树</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/"
           data-tag="pytorch"
           data-author="" >
            <span class="post-title" title="pytorch冻结网络模型">pytorch冻结网络模型</span>
            <span class="post-date" title="2022-11-08 09:49:41">2022/11/08</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E5%BC%80%E9%A2%98%E7%9B%B8%E5%85%B3/"
           data-tag="图像匹配"
           data-author="" >
            <span class="post-title" title="UAV和卫星图像配准思路">UAV和卫星图像配准思路</span>
            <span class="post-date" title="2022-11-08 09:49:41">2022/11/08</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/"
           data-tag="图像匹配"
           data-author="" >
            <span class="post-title" title="UAV和卫星图像配准论文阅读">UAV和卫星图像配准论文阅读</span>
            <span class="post-date" title="2022-11-08 09:49:41">2022/11/08</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Feature%20Matching/LoFTR/"
           data-tag="特征匹配"
           data-author="" >
            <span class="post-title" title="LoFTR代码">LoFTR代码</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/%E7%90%86%E8%A7%A3BN/"
           data-tag="batch norm"
           data-author="" >
            <span class="post-title" title="理解BN">理解BN</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="子空间论文阅读">子空间论文阅读</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/TENT/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="TENT论文阅读">TENT论文阅读</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/%E5%BC%80%E9%A2%98/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="TTA开题">TTA开题</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/%E6%B3%9B%E8%AF%BB/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="TTA论文泛读">TTA论文泛读</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/10/26/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"
           data-tag="目标检测"
           data-author="" >
            <span class="post-title" title="目标检测基础知识">目标检测基础知识</span>
            <span class="post-date" title="2022-10-26 15:49:06">2022/10/26</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/04/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Feature%20Matching/%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D/"
           data-tag="图像匹配"
           data-author="" >
            <span class="post-title" title="特征匹配论文">特征匹配论文</span>
            <span class="post-date" title="2022-04-10 16:52:31">2022/04/10</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/01/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/yolo/"
           data-tag="yolo"
           data-author="" >
            <span class="post-title" title="YOLO使用">YOLO使用</span>
            <span class="post-date" title="2022-01-01 13:23:06">2022/01/01</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/12/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E9%A3%9E%E6%9C%BA%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222)/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="飞机6D位姿估计">飞机6D位姿估计</span>
            <span class="post-date" title="2021-12-10 16:52:31">2021/12/10</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/11/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/SLAM%E5%8D%81%E5%9B%9B%E8%AE%B2/"
           data-tag="SLAM"
           data-author="" >
            <span class="post-title" title="SLAM十四讲代码bug及解决">SLAM十四讲代码bug及解决</span>
            <span class="post-date" title="2021-11-24 18:50:44">2021/11/24</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/11/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BA%8B%E4%BB%B6%E7%9B%B8%E6%9C%BA/%E8%B0%83%E7%A0%94/"
           data-tag="事件相机"
           data-author="" >
            <span class="post-title" title="事件相机调研">事件相机调研</span>
            <span class="post-date" title="2021-11-10 19:49:06">2021/11/10</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/10/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%A8%E5%8E%BB%E9%9B%BE/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE%E6%95%B4%E7%90%86/"
           data-tag="dehazing,haze removal"
           data-author="" >
            <span class="post-title" title="图像去雾去雨论文整理">图像去雾去雨论文整理</span>
            <span class="post-date" title="2021-10-22 12:00:00">2021/10/22</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%8D%AB%E6%98%9F%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="卫星姿态估计调研">卫星姿态估计调研</span>
            <span class="post-date" title="2021-10-20 09:49:41">2021/10/20</span>
        </a>
        
        
        <a  class="全部文章 位姿估计 "
           href="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222)/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="位姿估计基础及论文">位姿估计基础及论文</span>
            <span class="post-date" title="2021-10-20 09:49:41">2021/10/20</span>
        </a>
        
        
        <a  class="全部文章 软件使用 "
           href="/2021/10/08/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/%E5%85%B6%E4%BB%96/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="其他软件使用">其他软件使用</span>
            <span class="post-date" title="2021-10-08 09:49:41">2021/10/08</span>
        </a>
        
        
        <a  class="全部文章 软件使用 "
           href="/2021/09/23/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/ubuntu(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220829094535)/"
           data-tag="ubuntu"
           data-author="" >
            <span class="post-title" title="ubuntu相关">ubuntu相关</span>
            <span class="post-date" title="2021-09-23 10:29:44">2021/09/23</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/09/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%A8%E5%8E%BB%E9%9B%BE/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE/"
           data-tag="dehazing,heze removal"
           data-author="" >
            <span class="post-title" title="图像去雾">图像去雾</span>
            <span class="post-date" title="2021-09-23 10:29:44">2021/09/23</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/09/05/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/HDLBits%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"
           data-tag="verilog,数电"
           data-author="" >
            <span class="post-title" title="HDLBits刷题笔记">HDLBits刷题笔记</span>
            <span class="post-date" title="2021-09-05 11:16:10">2021/09/05</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/08/04/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/ZYNQ%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="ZYNQ,vivado"
           data-author="" >
            <span class="post-title" title="ZYNQ学习笔记">ZYNQ学习笔记</span>
            <span class="post-date" title="2021-08-04 19:03:34">2021/08/04</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/30/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/HLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="HLS"
           data-author="" >
            <span class="post-title" title="HLS学习笔记">HLS学习笔记</span>
            <span class="post-date" title="2021-07-30 10:15:16">2021/07/30</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/30/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/vivado2020-2%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"
           data-tag="vivado"
           data-author="" >
            <span class="post-title" title="vivado2020.2安装教程">vivado2020.2安装教程</span>
            <span class="post-date" title="2021-07-30 09:39:08">2021/07/30</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/23/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/%E3%80%90FPGA%E3%80%91%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"
           data-tag="图像处理"
           data-author="" >
            <span class="post-title" title="【FPGA】图像处理">【FPGA】图像处理</span>
            <span class="post-date" title="2021-07-23 14:52:46">2021/07/23</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/16/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/verilog%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="verilog,modelsim"
           data-author="" >
            <span class="post-title" title="verilog学习笔记">verilog学习笔记</span>
            <span class="post-date" title="2021-07-16 15:50:28">2021/07/16</span>
        </a>
        
        
        <a  class="全部文章 嵌入式和硬件 "
           href="/2021/03/13/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/%E3%80%90%E7%94%B5%E8%B5%9B%E3%80%91%E7%BA%BF%E8%B7%AF%E8%B4%9F%E8%BD%BD%E5%8F%8A%E6%95%85%E9%9A%9C%E6%A3%80%E6%B5%8B%E8%A3%85%E7%BD%AE/"
           data-tag="线路故障检测,自平衡电桥,正交解调，FPGA"
           data-author="" >
            <span class="post-title" title="【电赛】线路负载及故障检测装置">【电赛】线路负载及故障检测装置</span>
            <span class="post-date" title="2021-03-13 20:43:36">2021/03/13</span>
        </a>
        
        
        <a  class="全部文章 嵌入式和硬件 "
           href="/2021/03/12/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/%E3%80%90%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E3%80%91%E5%9F%BA%E4%BA%8EAtlas-200-DK%E7%9A%84%E9%9A%9C%E7%A2%8D%E7%89%A9%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"
           data-tag="Atlas,深度学习,神经网络,障碍物识别,目标识别"
           data-author="" >
            <span class="post-title" title="【本科毕业设计】基于Atlas_200_DK的障碍物识别系统设计与实现">【本科毕业设计】基于Atlas_200_DK的障碍物识别系统设计与实现</span>
            <span class="post-date" title="2021-03-12 19:20:57">2021/03/12</span>
        </a>
        
        
        <a  class="全部文章 软件使用 "
           href="/2021/02/12/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/%E5%B8%B8%E7%94%A8hexo%E5%8D%9A%E5%AE%A2%E6%93%8D%E4%BD%9C/"
           data-tag="hexo指令"
           data-author="" >
            <span class="post-title" title="常用hexo博客操作">常用hexo博客操作</span>
            <span class="post-date" title="2021-02-12 13:14:45">2021/02/12</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/01/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%8D%AB%E6%98%9F%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1review/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="卫星姿态估计综述">卫星姿态估计综述</span>
            <span class="post-date" title="2021-01-16 10:42:41">2021/01/16</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-计算机视觉/test_time_adaptation/Low Dimensional Trajectory Hypothesis is True" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">子空间论文阅读</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            <i class="iconfont icon-category"></i>
            
            
            <a  data-rel="计算机视觉">计算机视觉</a>
            
        </span>
        
        
        <span class="tag">
            <i class="iconfont icon-tag"></i>
            
            <a class="color1">test time adaptation</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2023-03-11 14:21:00'>2022-11-07 09:49</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Low-Dimensional-Trajectory-Hypothesis-is-True-DNNs-can-be-Trained-in-Tiny-Subspaces"><span class="toc-text">Low Dimensional Trajectory Hypothesis is True:DNNs can be Trained in Tiny Subspaces</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#INTRODUCTION"><span class="toc-text">INTRODUCTION</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RELATED-WORKS"><span class="toc-text">RELATED WORKS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DYNAMIC-LINEAR-DIMENSIONALITY-REDUCTION"><span class="toc-text">DYNAMIC LINEAR DIMENSIONALITY REDUCTION</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Motivation"><span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Methodology"><span class="toc-text">Methodology</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Training-Performance"><span class="toc-text">Training Performance</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DLDR-BASED-QUASI-NEWTON-ALGORITHM"><span class="toc-text">DLDR-BASED QUASI-NEWTON ALGORITHM</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hessian-Matrix-Approximation"><span class="toc-text">Hessian Matrix Approximation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Quasi-Newton-Update"><span class="toc-text">Quasi-Newton Update</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NUMERICAL-EXPERIMENTS"><span class="toc-text">NUMERICAL EXPERIMENTS</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Experiments-Setup"><span class="toc-text">Experiments Setup</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Verification-on-Various-Architectures"><span class="toc-text">Verification on Various Architectures</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Robustness-to-Label-Noise"><span class="toc-text">Robustness to Label Noise</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Improving-Well-trained-Models"><span class="toc-text">Improving Well-trained Models</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CONCLUSIONS-AND-FURTHER-WORKS"><span class="toc-text">CONCLUSIONS AND FURTHER WORKS</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-text">代码</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Low-Dimensional-Trajectory-Hypothesis-is-True-DNNs-can-be-Trained-in-Tiny-Subspaces"><a href="#Low-Dimensional-Trajectory-Hypothesis-is-True-DNNs-can-be-Trained-in-Tiny-Subspaces" class="headerlink" title="Low Dimensional Trajectory Hypothesis is True:DNNs can be Trained in Tiny Subspaces"></a>Low Dimensional Trajectory Hypothesis is True:DNNs can be Trained in Tiny Subspaces</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1E5411E71z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=0bb4d13f4bd26eaf7f64c37f29dc9f27">用最直观的方式告诉你：什么是主成分分析PCA_哔哩哔哩_bilibili</a></p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221117201516681.png" alt="image-20221117201516681" style="zoom:33%;"></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV16A411T7zX/?spm_id_from=333.788&amp;vd_source=0bb4d13f4bd26eaf7f64c37f29dc9f27">【学长小课堂】什么是奇异值分解SVD—SVD如何分解时空矩阵_哔哩哔哩_bilibili</a></p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221117201821493.png" alt="image-20221117201821493"></p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221117203502974.png" alt="image-20221117203502974" style="zoom:33%;"></p>
<p><strong>摘要：</strong>深度神经网络（DNN）通常包含大量参数，但存在冗余，因此可以猜测它们可以在低维子空间中训练。在本文中，我们提出了一种基于训练轨迹的低维特性的动态线性降维（DLDR）。简化方法是有效的，并得到了综合实验的支持：在40维空间中优化DNN可以在数千甚至数百万个参数上实现与常规训练相当的性能。由于只有几个变量需要优化，我们开发了一种有效的基于准牛顿的算法，获得了对标记噪声的鲁棒性，并提高了训练有素的模型的性能，三个后续实验，可以显示找到这种低维子空间的优势</p>
<h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>深度神经网络（DNN）在各个领域取得了前所未有的成功[1]，[2]。在DNN中，参数的数量通常非常大，例如，VGG11[3]中的28.5M，MobileNet[4]中的3.3M，Xception[5]中的21.0M。然而，简单地将DNN的每个参数视为独立变量太粗糙了。事实上，这些参数具有很强的相互关系。例如，梯度从深层传播到浅层，因此不同层之间的参数梯度密切相关。同一层中的参数也具有协同相关性。因此，独立优化变量的数量可能没有我们想象的那么多。换句话说，DNN似乎可以在相对低维的子空间中得到很好的训练，正如[6]首次提出的那样。<br>简而言之，DNN参数在训练中的依赖性和冗余性可以正式描述为以下假设。</p>
<p><strong>低维轨迹假说</strong><br>对于具有n个参数的神经网络，参数在训练过程中的轨迹可以近似地被具有d维的空间覆盖d≪ n。如果这一假设成立，那么学习在实践和理论方面都会有很大的好处。<br>假说是否成立的最佳标准是在这样的低维空间中的优化是否可以实现与优化原始空间中的所有参数相同或相似的性能。<br>在开创性工作[7]中，作者将SGD训练在全参数上的90%准确度设置为标准，并发现所需的内在维度远小于参数的数量。例如，在CIFAR-10[8]上，具有62006个参数的LeNet[9]可以在2900维子空间中进行优化，获得的精度为常规训练的90%。尽管通过随机投影提取子空间的方法是初步的，但其性能非常有希望。随后，[10]考虑了网络的不同部分，并在每一步重新绘制随机基，进一步将所需维度减少到数百，但精度降级仍然类似。<br>但现有的工作部分不完全支持低维轨迹假设，因为与常规的全参数训练相比仍有很大差距。在本文中，我们建议通过分析动态轨迹来提取子空间，而不是[7]，[10]中的随机投影。通过所提出的方法，许多标准的神经网络结构可以<strong>仅由40个独立变量很好地训练，并且性能几乎与全参数上的常规训练相同</strong>，这表明<strong>DNN可以在低维子空间中训练</strong>，我们确实可以有效地找到这样的子空间。</p>
<p>为了直观地说明假设和我们的目标，我们可以考虑参数为w∈Rn的DNN f(x，w)。<br>它的训练序列，即训练轨迹，可以表示为{wi}i=0，…，t，其中wi是指训练步骤i的w值。这个假设意味着我们可以找到一个子空间(实际上，它是一个仿射集，但我们稍后将进行集中化；因此，我们在本文中没有严格区分这两个概念)来近似覆盖优化轨迹{wi}i=0，…，t。这种现象与神经切核(NTK)[11]，[12]的低阶性质和顶子空间[6]的集中梯度有关，这将在3.1节中讨论。<br>请注意，提取子空间，即<strong>寻找独立变量（自变量），不同于在模型简化方法中选择参数</strong>，例如参见[13]、[14]。考虑图1中的一个玩具示例，其中包含三个需要优化的变量。如图所示，优化轨迹在e1和e2跨越的子空间中，即优化轨迹的维度为2，但没有单个参数可以减少。这个简单的例子显示了我们的关注点：我们的目标是找到合适的参数组合来构造低维子空间中的自变量。</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221117210137300.png" alt="image-20221117210137300" style="zoom:33%;"></p>
<p><em>图1：有三个参数w(1)、w(2)、w(3)需要优化。</em><br><em>但是训练轨迹{wi}i=0，…，t可以在由e1和e2跨越的二维子空间中。如果是这样的话，在低维空间中的训练可以具有与在高维空间中的训练相当的性能。</em></p>
<p>为了找到覆盖训练轨迹的子空间，人们应该关注训练轨迹。因此，我们将所提出的子空间提取方法命名为动态线性降维(DLDR)。利用DLDR得到的独立变量（自变量），我们可以很好地刻画只有几个基(自变量)的子空间中的训练轨迹。在第五节中，大量的数值实验将表明，许多标准的DNN结构只需40个自变量就可以很好地进行训练。同时，测试精度可以保持与在原始空间中对全参数进行常规训练几乎相同的精度。<br>从理论上讲，即使在训练集不是很大的情况下，将数百万个参数减少到几个自变量就可以解释DNN良好的泛化性能。在实际应用中，由于只需要对几个自变量进行优化，我们可以<strong>使用二阶方法而不是一阶优化方法（?）</strong>，如SGD[15]，以克服一些固有的缺点，如尺度敏感性和收敛速度慢。在现有的工作中，引入了<strong>动量等部分二阶信息</strong>，极大地提高了DNN的性能，导致了目前流行的自适应策略，如Adam[16]，RMSprop[17]等。由于DLDR发现的低维子空间，拟牛顿方法，如DFP和BFGS[18]，[19]，变得适用于DNN的训练。本文提出了一种投影子空间上的BFGS算法，称为P-BFGS算法，<strong>比SGD算法节省了约30%的时间</strong>。<br>低维轨迹假设的另一个后续应用是<strong>提高模型对标签噪声的稳健性</strong>。由于DNN是在过度参数化的制度下工作，它们可以很容易地适应任何标签，甚至是不正确或无意义的标签[20]。因此，当训练标签被噪声破坏时，DNN很容易被破坏。现在，由于我们已经发现了非常低维的子空间，随着训练自由度的显著降低，在这样的子空间中训练DNN有望对标签噪声具有更强的鲁棒性。在5.4节中，我们将发现，在没有任何其他稳健性增强技术的情况下，低维子空间的训练在CIFAR-10上可以达到<strong>50%以上的测试精度，即使90%的训练标签是随机设置的</strong>。<br>本文最重要的贡献是验证了低维轨迹假设，这表明在低维子空间中优化DNN可以在所有参数上获得与训练相似的性能。<br>具体贡献包括：子空间提取方法和提取低维子空间的三个后续优势：</p>
<p>·动态线性降维技术，以有效地找到低维子空间；</p>
<p>·通过在低维子空间中使用基于准牛顿的算法来节省训练时间；</p>
<p>·通过在低维子空间中进行训练来对标签噪声具有鲁棒性；</p>
<p>·通过子空间训练来提高训练有素的模型的性能。<br>本文的其余部分组织如下。我们首先回顾了第二节中的相关工作。然后在第三节中提出并验证了低维轨迹假设的DLDR算法。在第四节中，我们设计了一个基于DLDR的拟牛顿算法。然后在第五节中我们对降维性能进行了评估。第六节进行了简要的讨论。代码已发布1<a target="_blank" rel="noopener" href="https://github.com/nblt/DLDR。">https://github.com/nblt/DLDR。</a></p>
<h3 id="RELATED-WORKS"><a href="#RELATED-WORKS" class="headerlink" title="RELATED WORKS"></a>RELATED WORKS</h3><p>分析和理解DNN优化目标的前景非常重要。例如，Li等人[21]使用一系列可视化方法可视化DNN的损失情况。他等人[22]观察到，在局部最优点存在许多不对称方向，沿着这些方向，损耗在一侧急剧增加，在另一侧缓慢增加。一个重要方面是衡量DNN景观的内在维度。在开创性工作[7]中，发现使用随机投影，在缩减子空间中的优化可以达到常规SGD训练的90%性能。在此基础上，提出了内在维数远小于参数数量的观点。<br>下面的工作[10]通过考虑网络的不同部分并在每个步骤重新绘制随机基来提高随机基训练性能。<br>与之前的工作不同，我们通过分析DNN的训练动态来提取子空间，然后得到了显著的改进：固有维数降低了一个数量级，并且精度提高到与常规训练几乎相同。<br>验证低维轨迹假设并找到可以很好地训练DNN的微小子空间非常重要，不仅对于理解DNN的学习，而且对于设计强大的优化方法也非常重要。这与[6]中的发现一致，即在短时间的训练之后，DNN的梯度可以收敛到一个非常小的子空间，该子空间由Hessian矩阵的几个顶部特征向量覆盖。在实践中，低维轨迹假设可能会激发更强大的优化方法，并带来更多潜力来克服学习中的一些现有障碍。由于在极小的子空间中，优化变量的数量大大减少，因此可以以相对简单的方式利用高阶信息。在[23]、[24]等中，设计了精细的方法来使用曲率信息，同时保持计算效率，然而，这是一个不相容的矛盾，除非可以有效减少优化变量的数量。另一个密切相关的方向是低级训练[25]，[26]或更新[27]，[28]。例如，LoRA[28]通过学习低秩参数矩阵来更新预训练的模型，提高了微调大型语言模型的效率。虽然这些方法侧重于参数矩阵的静态低秩结构或它们的自适应，但我们利用了训练动力学的低秩特性，并且是这些方法的补充，这可以带来进一步的可能效率</p>
<h3 id="DYNAMIC-LINEAR-DIMENSIONALITY-REDUCTION"><a href="#DYNAMIC-LINEAR-DIMENSIONALITY-REDUCTION" class="headerlink" title="DYNAMIC LINEAR DIMENSIONALITY REDUCTION"></a>DYNAMIC LINEAR DIMENSIONALITY REDUCTION</h3><h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p><strong>本文的主要目标是指出并验证DNN中参数的自由度相当低</strong>。这可以简洁地表示为参数的轨迹在低维空间中的假设。<br>在一项开创性的工作[6]中，作者发现在低维随机选择的空间中进行训练仍然可以产生有意义的神经网络。具体而言，原始空间中的参数w∈ Rn在d维空间v∈ Rd中更新:</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118101647594.png" alt="image-20221118101647594" style="zoom:35%;"></p>
<p>其中P∈ Rn×d是一个随机逆投影矩阵。很明显，（1）中只有d个自由度。如[23]中的数值验证，即使在d≪ n、 （1）可以输出有意义的结果。这里，我们说“有意义”是指<strong>性能比初始化好得多，但比完全训练后的网络效果更差。</strong>[10]中通过用启发式方法替换随机投影，提高了性能。在这些低维空间中的训练性能可以在表1中观察到，表1部分但不完全支持DNN可以在低维空间训练的假设。<br>为了研究训练轨迹和低维景观，我们可以使用神经切线核（NTK），它理想地将单输出神经网络的梯度流公式化如下</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118102107485.png" alt="image-20221118102107485" style="zoom:33%;"></p>
<p>（公式看不懂。。。先跳过）</p>
<p>基于上述有趣的观察，我们正式提出了第1节中给出的<strong>低维轨迹假设说</strong>。数学上，对于参数的轨迹w0，w1，…，wt，…，低维轨迹假说声称存在低维轨迹v1，v2，…，vt，…和投影P∈ Rn×d使得</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118102632722.png" alt="image-20221118102632722" style="zoom:33%;"></p>
<p>该假设侧重于神经网络的训练，其验证是直接的，即，<strong>如果神经网络可以在d维空间中很好地训练，那么低维轨迹假设是正确的。</strong></p>
<p>如前所述，现有的工作现在只能部分验证该假设，因为在他们提取的子空间上进行训练，神经网络可以被训练为有意义的解决方案，但结果仍然比在整个参数空间上的训练差得多。在下文中，我们将提出一种新的方法来找到神经网络可以很好地训练的低维空间。<br>该结果验证了低维轨迹假设，有望为神经网络带来新的理解，例如泛化能力、隐式正则化、高效学习算法等。</p>
<h4 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h4><p>降维的关键问题是找到近似覆盖参数轨迹的低维子空间。<strong>代替处理连续轨迹，我们实际上使用其离散化，即离散采样点来表征轨迹</strong>。基本操作包括:</p>
<ul>
<li>首先，对训练过程中神经网络参数的t步进行采样，即{w1，w2，.。。。，wt}。</li>
<li>第二，中心化样本，即求样本集参数的均值，并且每个参数减去均值得到W</li>
<li>第三，找出由d维子空间P=[e1，e2，.。。。，ed]来涵盖W.请注意，在DNN中，参数n的数目通常显著大于t和d。</li>
</ul>
<p>第三步是找到一个子空间，该子空间最小化从W的列向量到该子空间的距离之和。利用l2范数，可以将其公式化为最大化W的投影方差，即。</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118112111041.png" alt="image-20221118112111041" style="zoom:33%;"></p>
<p>这是一个标准的PCA问题，但计算维度太大，可以使用SVD分解来减少计算量：</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118112323474.png" alt="image-20221118112323474" style="zoom:33%;"></p>
<p>DLDR算法总流程：</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118112351688.png" alt="image-20221118112351688" style="zoom:33%;"></p>
<h4 id="Training-Performance"><a href="#Training-Performance" class="headerlink" title="Training Performance"></a>Training Performance</h4><p>基于优化轨迹近似位于低维子空间的假设，所提出的DLDR可以将优化空间的维数从n降到d。为了验证该假设，我们在这样的低维子空间中优化DNN，检查其性能是否与原始空间中所有参数的训练相似。<br>首先，我们为CIFAR-10进行了训练ResNet8[31]的实验，这也是开创性工作[10]所考虑的。如上所述，验证低维轨迹假设的标准是比较子空间和全参数空间中的训练性能，为此，我们使用SGD训练ResNet8的78330个参数。详细设置为：学习率为0.1，批量大小为128。请注意，在本文的实验中，SGD始终包含动量项，此处动量参数为0.9。经过3次试验，SGD平均获得83.84%的测试精度。<br>然后，我们应用DLDR从参数中提取低维子空间，方法是在SGD训练的30个时期内对轨迹进行采样。详细的采样策略是在每个历元训练之后对模型参数进行采样。在图2a中，绘制了前5个预测成分的方差比，显示总方差的90%以上属于这五个成分。这一观察结果与我们关于存在这样一个低维子空间的假设一致，该子空间可以近似覆盖优化轨迹。</p>
<p>接下来，<strong>在DLDR提取的子空间中，我们从头开始训练神经网络</strong>。我们在这里设置的维度是15，我们在<strong>投影子空间中使用SGD优化器，称为P-SGD</strong>。为了避免公平性的其他影响，我们使用与常规SGD相同的超参数设置，并从相同的初始化开始。从图2b中可以看出，当DLDR采样停止时，P-SGD很快就超过了性能（因此P-SGD的良好性能不是来自DLDR采样阶段给出的可通过的解决方案），并达到了与常规SGD相似甚至更好的精度。这里，与SGD相比的优势可能来自低维子空间的去噪（方差降低）效果，并且可以进一步研究。然而，至少，它表明我们可以在具有<strong>显著较低维度（即15）</strong>的子空间中有效地训练CIFAR-10的ResNet8，这有力地支持了我们的假设，即优化轨迹可以近似地位于低维子空间中。<br>在表1中，我们报告了用于优化的维度和测试精度。在[7]中，7982个维度被用于实现平均58.35%的准确度，在[10]中提高到70.26。现在，DLDR可以找到一个维数更少的子空间，并获得更好的精度。在第5节中，我们将考虑更复杂的DNN架构和更复杂的任务，以进一步验证低维轨迹假设。</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118135412861.png" alt="image-20221118135412861" style="zoom:33%;"></p>
<h3 id="DLDR-BASED-QUASI-NEWTON-ALGORITHM"><a href="#DLDR-BASED-QUASI-NEWTON-ALGORITHM" class="headerlink" title="DLDR-BASED QUASI-NEWTON ALGORITHM"></a>DLDR-BASED QUASI-NEWTON ALGORITHM</h3><p>由于DNN通常有大量的参数需要优化，<strong>一阶方法，即基于梯度下降的方法</strong>是主要的方法。然而，一阶方法存在一些基本的局限性，例如围绕<strong>最优点的收敛速度慢，以及对学习速率的高度敏感性</strong>。二阶方法可以解决对于这些问题，但由于计算量大，应用它们来训练包含大量参数的DNN存在很大困难。取而代之的是，只使用部分二阶信息，如动量和累积信息，从而产生了许多流行的训练算法，如Adam[16]、RMSprop[17]和AdaGrad[32]，[33]。现在，使用所提出的DLDR，可以只找到几个（几十个）独立变量进行优化，这使得在训练复杂DNN时使用二阶方法变得适用。遵循这一思想，我们基于BFGS的框架开发了一种拟牛顿方法[18]，[19]。类似地，主要步骤包括基于历史梯度的黑森矩阵近似、拟牛顿更新和回溯线搜索，其详细信息在以下小节中给出。</p>
<h4 id="Hessian-Matrix-Approximation"><a href="#Hessian-Matrix-Approximation" class="headerlink" title="Hessian Matrix Approximation"></a>Hessian Matrix Approximation</h4><p>（可见slam十四讲p127）</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118141342146.png" alt="image-20221118141342146" style="zoom:33%;"></p>
<ol>
<li>将参数的梯度投影到自变量空间；</li>
<li>在自变量空间中计算牛顿方向；</li>
<li>在训练过程中保持投影矩阵不变，将牛顿方向反投影到原始参数空间。</li>
</ol>
<h4 id="Quasi-Newton-Update"><a href="#Quasi-Newton-Update" class="headerlink" title="Quasi-Newton Update"></a>Quasi-Newton Update</h4><p>虽然我们能找到只有几个独立变量来优化，但它们的梯度是通过在当前DNN框架中投影原始参数的梯度来计算的。因此，直接计算二阶梯度仍然不切实际。或者，我们采用拟牛顿方法来逼近Hessian矩阵及其逆矩阵。以这种方式，标准BFGS算法[18]，[19]与秩2校正更新一起使用，如下所示</p>
<p>（没看懂）</p>
<h3 id="NUMERICAL-EXPERIMENTS"><a href="#NUMERICAL-EXPERIMENTS" class="headerlink" title="NUMERICAL EXPERIMENTS"></a>NUMERICAL EXPERIMENTS</h3><p>在介绍了实验设置之后，我们将在本节中对以下方面进行数值评估。（1） 我们应用P-SGD来训练子空间中的DNN，其中<strong>维数固定为40</strong>，由DLDR提取，以验证不同神经网络架构上的低维轨迹假设。（2） 我们评估了所提出的P-BFGS算法的性能，并显示了其在加速训练方面的潜力。（3） 我们用标签噪声进行了实验，以证明从子空间训练中获得的<strong>固有鲁棒性</strong>。（4） 我们在<strong>训练有素的网络上应用DLDR</strong>，以进一步提高其性能</p>
<h4 id="Experiments-Setup"><a href="#Experiments-Setup" class="headerlink" title="Experiments Setup"></a>Experiments Setup</h4><p>我们实验中使用的数据集包括CIFAR-10、CIFAR-100[8]和ImageNet[41]。对于CIFAR，所有图像均通过通道平均值和方差进行归一化。数据增强[31]也被执行：概率为0.5的水平图像翻转、4像素填充和裁剪。<br>我们测试了ResNet20和ResNet32[31]以及其他11种DNN架构。这些网络中全参数的数量从0.27M到28.5M，但本文中我们始终只选择40个自变量。我们使用SGD优化器来训练DNN，其中权重衰减设置为1e-4，动量参数设置为0.9，批量大小设置为128。默认的初始学习率设置为0.1。对于CIFAR-10，我们训练DNN 150个时期，并在100个时期将学习率除以10，而对于CIFAR-100，我们训练200个时期，在150个时期进行除法。对于ImageNet，我们的代码是从官方PyTorch示例2修改而来的。实验是在Nvidia Geforce GTX 2080 TI上进行的。<br>我们为CIFAR使用一个GPU，为ImageNet使用四个GPU。5个独立试验的平均值和标准差。DLDR和实验设置的更详细分析见附录。<br>DLDR需要对优化轨迹进行采样。<strong>对于CIFAR，我们采用最简单的采样策略：在每个训练周期之后对模型参数进行采样。对于ImageNet，参数在每个训练时期被均匀采样3次。更精细的采样策略可以提高性能。</strong><br>对于P-SGD，我们采用与SGD相同的批量大小和动量因子。我们将初始学习率设置为1，训练时期设置为40，并在30个时期将学习率除以10。对于P-BFGS，我们将CIFAR的批大小设置为1024，ImageNet的批大小为256。请注意，这种二阶方法不需要学习速率表。</p>
<h4 id="Verification-on-Various-Architectures"><a href="#Verification-on-Various-Architectures" class="headerlink" title="Verification on Various Architectures"></a>Verification on Various Architectures</h4><p>在第3.3小节中，在CIFAR10上进行了实验，在此我们验证了CIFAR-100上的低维轨迹假设。我们将分别在所有参数和缩减子空间（后者实际上是建议的P-SGD）中通过SGD训练DNN。对于不同的神经网络架构，我们总是选择40个独立变量。如果SGD和P-SGD给出了可比的性能，则支持我们的假设，同时验证了所提出的DLDR的有效性。该实验包含11个流行的DNN，包括VGG11[3]、DenseNet121[42]、Inception[43]、NasNet[44]等，参数数量从780K到28.5M不等。<br>在表2中，我们使用具有50/100/200个时期的SGD报告了测试精度，200个时期后的测试精度作为基线。然后，我们在40D子空间中应用P-SGD，DLDR从50或100个时期采样中提取这些子空间，并从初始化中进行40个时期的训练。</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118144500074.png" alt="image-20221118144500074" style="zoom:33%;"></p>
<p>见表2中最后一列的结果。它清楚地表明，具有40个自变量的P-SGD可以在整个参数上达到SGD的竞争性能。<br>这种竞争性能适用于所有这些架构，并有力地支持我们的低维轨迹假设。<br>一个次要的发现是，一般来说，如果更好地提取子空间，性能会更好</p>
<p><strong>Performance of P-BFGS Algorithm</strong></p>
<p>在实证证明了低维轨迹假设之后，我们现在尝试一种二阶算法，即P-BFGS。我们首先考虑CIFAR-10上的ResNet20[31]。在图3a中，绘制了SGD的训练和测试精度曲线。灰色区域表示我们从何处获取DLDR样本，然后提取自变量。在获得40个自变量后，我们使用P-BFGS从相同的初始化开始，并绘制图3b中的训练曲线。仅<strong>在2个时期后</strong>，P-BFGS就比SGD（50个时期，即DLDR的采样）获得了更好的性能，并且在10个时期内，P-BFG达到了SGD（150个时期）的性能，这初步证明了应用二阶方法在效率上的优势</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118144822572.png" alt="image-20221118144822572" style="zoom:50%;"></p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118145401179.png" alt="image-20221118145401179" style="zoom:33%;"></p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118145518248.png" alt="image-20221118145518248" style="zoom:33%;"></p>
<h4 id="Robustness-to-Label-Noise"><a href="#Robustness-to-Label-Noise" class="headerlink" title="Robustness to Label Noise"></a>Robustness to Label Noise</h4><p>（这里没有说子空间是从哪里得到的，从带噪数据训练的参数中得到还是<strong>干净数据</strong>？）</p>
<p>由于DNN的插值本质，它们对标签噪声敏感，即当标签不正确时，DNN将跟随这些不正确且无意义的标签。更糟糕的是，区分DNN学习的标签是正确的还是错误的，没有明显的区别[20]。目前，可以使用提前停止[50]（<strong>即防止过拟合</strong>），但如何选择最佳停止仍然具有挑战性，因为即使验证数据也可能损坏。在验证了DNN可以在低维子空间中训练之后，我们期望<strong>低维属性可以自然地为DNN带来对标签噪声的鲁棒性。</strong><br>为了检查<strong>标签噪声</strong>下的性能，我们考虑CIFAR-10，并将随机标签分配给训练数据的一部分c（针对不同的方法随机选择并固定）。然后，我们用损坏的数据训练ResNet20模型。有了标签噪声，SGD的完整训练性能显著下降，如图5中的蓝色曲线所示。提前停止（红色曲线）确实有帮助，但对干净数据的测试精度较差（c=0）。<br>在低维子空间（绿色曲线）中的训练可以以较大的优势持续优于早期停止，同时在干净数据上保持与常规训练相同的性能。注意，这里我们在没有任何增强技术的情况下获得了鲁棒性，例如，对损失函数的修改[51]，[52]，因此结果有望通过这些技术进一步改进。</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118145913877.png" alt="image-20221118145913877" style="zoom:40%;"></p>
<p>P-SGD对标签噪声的鲁棒性来自于训练子空间的低维特性，或者换句话说，<strong>训练的自由度非常小</strong>。为了进一步研究自变量数量的影响，我们将d从10变化到40，并在表4中报告了测试精度。在不同的标签噪声水平下，完全训练的PSGD（即，我们不选择提前停止）总是比完全训练的SGD具有更好的精度。<br>我们还提供SGD获得的最佳精度，即，我们在训练期间监控测试精度，并选择出现的最佳测试精度。当然，在实践中无法达到SGD（最佳），但它可以作为一个参考，表明在低维子空间中训练DNN对标记噪声是鲁棒的。</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118150612211.png" alt="image-20221118150612211" style="zoom:40%;"></p>
<h4 id="Improving-Well-trained-Models"><a href="#Improving-Well-trained-Models" class="headerlink" title="Improving Well-trained Models"></a>Improving Well-trained Models</h4><p>在本小节中，我们研究了从井训练阶段提取的子空间。我们从在ImageNet上训练有素的ResNet18\/50开始[41]（来自torchvision.models）。<br>在表5中，他们的准确度显示为“训练有素”。这里，“训练有素”意味着继续进行最初的SGD培训无法提高绩效。现在我们提取具有30维的子空间（以0.005的学习率从SGD的5/10/15个时期采样），并应用P-BFGS。在这一阶段，解决方案接近最佳状态，前景更加平坦。因此，采样时间和维度可能比以前的实验少。由于在训练阶段获得了几个解决方案，<strong>随机加权平均</strong>（SWA，[53]）是一种有效且普遍采用的泛化改进方法，是适用的，我们将其性能作为比较。可以观察到，经过训练的模型可以通过子空间优化进一步改进，性能优于SWA</p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221118150810037.png" alt="image-20221118150810037" style="zoom:33%;"></p>
<h4 id="CONCLUSIONS-AND-FURTHER-WORKS"><a href="#CONCLUSIONS-AND-FURTHER-WORKS" class="headerlink" title="CONCLUSIONS AND FURTHER WORKS"></a>CONCLUSIONS AND FURTHER WORKS</h4><p>本文的主要主张是低维轨迹假设。基于训练动力学，我们设计了一种高效的降维方法DLDR。在综合实验中，优化DLDR提取的几个（例如，几十个）独立变量可以获得与全参数常规训练类似的性能。<br>优化性能和降维都从先前的工作中得到了显著改善[7]，[10]，有力地支持了这一假设，并表明DNN可以在很小的子空间中得到很好的训练。<br>从DNN训练的新视角出发，我们尝试了三种后续应用，以进一步支持我们的假设，并获得了巨大的好处：1）随着维数的大幅减少，二阶方法变得适用，从中我们设计了P-BFGS算法，并为训练带来了极大的效率；2） 在低维子空间中的训练自然会给标签噪声带来鲁棒性；3） 我们还表明，子空间训练可以显著提高训练有素的模型的性能。这些应用进一步支持低维轨迹假设。<br>尽管它们非常简单，例如，使用原始的BFGS框架，没有任何增强技术，但它们的性能意味着找到这样的低维子空间可以有助于理论和实践学习。进一步工作的可能方向包括<strong>将子空间训练应用于微调任务</strong>[27]，[28]，结合其他低秩训练方法[25]，[26]，以了解过度拟合、过度参数化[54]，并研究少数镜头学习[55]、元学习[56]等。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/anshuai_aw1/article/details/82498374?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-82498374-blog-119275175.pc_relevant_3mothn_strategy_recovery&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-82498374-blog-119275175.pc_relevant_3mothn_strategy_recovery&amp;utm_relevant_index=1">https://blog.csdn.net/anshuai_aw1/article/details/82498374?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-82498374-blog-119275175.pc_relevant_3mothn_strategy_recovery&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-82498374-blog-119275175.pc_relevant_3mothn_strategy_recovery&amp;utm_relevant_index=1</a></p>
<p><img src="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/image-20221125171645874.png" alt="image-20221125171645874"></p>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 jaytp@qq.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>






    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2016-2020 Yelog
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
