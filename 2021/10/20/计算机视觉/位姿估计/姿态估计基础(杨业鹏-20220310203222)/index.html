<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>位姿估计基础及论文 | young&#39;s blog</title>
  <meta name="keywords" content=" 位姿估计 ">
  <meta name="description" content="位姿估计基础及论文 | young&#39;s blog">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="Oops～，我崩溃了！找不到你想要的页面了">
<meta property="og:type" content="website">
<meta property="og:title" content="404">
<meta property="og:url" content="https://youngyyp.github.io/404.html">
<meta property="og:site_name" content="young&#39;s blog">
<meta property="og:description" content="Oops～，我崩溃了！找不到你想要的页面了">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-02-23T11:37:07.000Z">
<meta property="article:modified_time" content="2021-02-10T02:51:50.601Z">
<meta property="article:author" content="young">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.png">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 6.0.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="young's blog" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism.css" type="text/css"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/1.png"/>
</a>
<div class="author">
    <span>young</span>
</div>

<div class="icon">
    
</div>




<ul>
    <li>
        <div class="all active" data-rel="全部文章">全部文章
            
                <small>(40)</small>
            
        </div>
    </li>
    
        
            
                <li>
                    <div data-rel="计算机视觉">
                        
                        计算机视觉
                        <small>(20)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="嵌入式和硬件">
                        
                        嵌入式和硬件
                        <small>(2)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="软件使用">
                        
                        软件使用
                        <small>(3)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="CPP">
                        
                        CPP
                        <small>(9)</small>
                        
                    </div>
                    
                </li>
            
        
    
        
            
                <li>
                    <div data-rel="FPGA">
                        
                        FPGA
                        <small>(6)</small>
                        
                    </div>
                    
                </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
    </div>
    <div>
        
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="40">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>目标检测</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>目标识别</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>深度学习</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>神经网络</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>事件相机</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>数电</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>特征匹配</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>图像处理</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>图像匹配</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>位姿估计</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>线路故障检测</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>障碍物识别</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>正交解调，FPGA</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>自平衡电桥</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Atlas</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>batch norm</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>dehazing</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>haze removal</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>hexo指令</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>heze removal</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>HLS</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>modelsim</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>pytorch</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>SLAM</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>test time adaptation</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>ubuntu</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>verilog</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>vivado</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>yolo</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>ZYNQ</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="动态规划">动态规划</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%AD%97%E7%AC%A6%E4%B8%B2/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="字符串">字符串</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E6%95%B0%E7%BB%84/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="数组">数组</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="贪心算法">贪心算法</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E9%93%BE%E8%A1%A8/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="链表">链表</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%93%88%E5%B8%8C%E8%A1%A8/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="哈希表">哈希表</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E5%9B%9E%E6%BA%AF/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="回溯">回溯</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="栈与队列">栈与队列</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 CPP "
           href="/2023/02/01/cpp/%E4%BA%8C%E5%8F%89%E6%A0%91/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="二叉树">二叉树</span>
            <span class="post-date" title="2023-02-01 21:14:33">2023/02/01</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/"
           data-tag="pytorch"
           data-author="" >
            <span class="post-title" title="pytorch冻结网络模型">pytorch冻结网络模型</span>
            <span class="post-date" title="2022-11-08 09:49:41">2022/11/08</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E5%BC%80%E9%A2%98%E7%9B%B8%E5%85%B3/"
           data-tag="图像匹配"
           data-author="" >
            <span class="post-title" title="UAV和卫星图像配准思路">UAV和卫星图像配准思路</span>
            <span class="post-date" title="2022-11-08 09:49:41">2022/11/08</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/UAV&Satellite/%E8%B0%83%E7%A0%94/"
           data-tag="图像匹配"
           data-author="" >
            <span class="post-title" title="UAV和卫星图像配准论文阅读">UAV和卫星图像配准论文阅读</span>
            <span class="post-date" title="2022-11-08 09:49:41">2022/11/08</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Feature%20Matching/LoFTR/"
           data-tag="特征匹配"
           data-author="" >
            <span class="post-title" title="LoFTR代码">LoFTR代码</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/%E7%90%86%E8%A7%A3BN/"
           data-tag="batch norm"
           data-author="" >
            <span class="post-title" title="理解BN">理解BN</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/Low%20Dimensional%20Trajectory%20Hypothesis%20is%20True/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="子空间论文阅读">子空间论文阅读</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/TENT/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="TENT论文阅读">TENT论文阅读</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/%E5%BC%80%E9%A2%98/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="TTA开题">TTA开题</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/11/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/test_time_adaptation/%E6%B3%9B%E8%AF%BB/"
           data-tag="test time adaptation"
           data-author="" >
            <span class="post-title" title="TTA论文泛读">TTA论文泛读</span>
            <span class="post-date" title="2022-11-07 09:49:41">2022/11/07</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/10/26/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"
           data-tag="目标检测"
           data-author="" >
            <span class="post-title" title="目标检测基础知识">目标检测基础知识</span>
            <span class="post-date" title="2022-10-26 15:49:06">2022/10/26</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/04/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Feature%20Matching/%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D/"
           data-tag="图像匹配"
           data-author="" >
            <span class="post-title" title="特征匹配论文">特征匹配论文</span>
            <span class="post-date" title="2022-04-10 16:52:31">2022/04/10</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2022/01/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/yolo/"
           data-tag="yolo"
           data-author="" >
            <span class="post-title" title="YOLO使用">YOLO使用</span>
            <span class="post-date" title="2022-01-01 13:23:06">2022/01/01</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/12/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E9%A3%9E%E6%9C%BA%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222)/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="飞机6D位姿估计">飞机6D位姿估计</span>
            <span class="post-date" title="2021-12-10 16:52:31">2021/12/10</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/11/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/SLAM%E5%8D%81%E5%9B%9B%E8%AE%B2/"
           data-tag="SLAM"
           data-author="" >
            <span class="post-title" title="SLAM十四讲代码bug及解决">SLAM十四讲代码bug及解决</span>
            <span class="post-date" title="2021-11-24 18:50:44">2021/11/24</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/11/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BA%8B%E4%BB%B6%E7%9B%B8%E6%9C%BA/%E8%B0%83%E7%A0%94/"
           data-tag="事件相机"
           data-author="" >
            <span class="post-title" title="事件相机调研">事件相机调研</span>
            <span class="post-date" title="2021-11-10 19:49:06">2021/11/10</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/10/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%A8%E5%8E%BB%E9%9B%BE/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE%E6%95%B4%E7%90%86/"
           data-tag="dehazing,haze removal"
           data-author="" >
            <span class="post-title" title="图像去雾去雨论文整理">图像去雾去雨论文整理</span>
            <span class="post-date" title="2021-10-22 12:00:00">2021/10/22</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%8D%AB%E6%98%9F%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="卫星姿态估计调研">卫星姿态估计调研</span>
            <span class="post-date" title="2021-10-20 09:49:41">2021/10/20</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222)/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="位姿估计基础及论文">位姿估计基础及论文</span>
            <span class="post-date" title="2021-10-20 09:49:41">2021/10/20</span>
        </a>
        
        
        <a  class="全部文章 软件使用 "
           href="/2021/10/08/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/%E5%85%B6%E4%BB%96/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="其他软件使用">其他软件使用</span>
            <span class="post-date" title="2021-10-08 09:49:41">2021/10/08</span>
        </a>
        
        
        <a  class="全部文章 软件使用 "
           href="/2021/09/23/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/ubuntu(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220829094535)/"
           data-tag="ubuntu"
           data-author="" >
            <span class="post-title" title="ubuntu相关">ubuntu相关</span>
            <span class="post-date" title="2021-09-23 10:29:44">2021/09/23</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/09/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%A8%E5%8E%BB%E9%9B%BE/%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE/"
           data-tag="dehazing,heze removal"
           data-author="" >
            <span class="post-title" title="图像去雾">图像去雾</span>
            <span class="post-date" title="2021-09-23 10:29:44">2021/09/23</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/09/05/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/HDLBits%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"
           data-tag="verilog,数电"
           data-author="" >
            <span class="post-title" title="HDLBits刷题笔记">HDLBits刷题笔记</span>
            <span class="post-date" title="2021-09-05 11:16:10">2021/09/05</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/08/04/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/ZYNQ%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="ZYNQ,vivado"
           data-author="" >
            <span class="post-title" title="ZYNQ学习笔记">ZYNQ学习笔记</span>
            <span class="post-date" title="2021-08-04 19:03:34">2021/08/04</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/30/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/HLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="HLS"
           data-author="" >
            <span class="post-title" title="HLS学习笔记">HLS学习笔记</span>
            <span class="post-date" title="2021-07-30 10:15:16">2021/07/30</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/30/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/vivado2020-2%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"
           data-tag="vivado"
           data-author="" >
            <span class="post-title" title="vivado2020.2安装教程">vivado2020.2安装教程</span>
            <span class="post-date" title="2021-07-30 09:39:08">2021/07/30</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/23/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/%E3%80%90FPGA%E3%80%91%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"
           data-tag="图像处理"
           data-author="" >
            <span class="post-title" title="【FPGA】图像处理">【FPGA】图像处理</span>
            <span class="post-date" title="2021-07-23 14:52:46">2021/07/23</span>
        </a>
        
        
        <a  class="全部文章 FPGA "
           href="/2021/07/16/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/FPGA/verilog%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="verilog,modelsim"
           data-author="" >
            <span class="post-title" title="verilog学习笔记">verilog学习笔记</span>
            <span class="post-date" title="2021-07-16 15:50:28">2021/07/16</span>
        </a>
        
        
        <a  class="全部文章 嵌入式和硬件 "
           href="/2021/03/13/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/%E3%80%90%E7%94%B5%E8%B5%9B%E3%80%91%E7%BA%BF%E8%B7%AF%E8%B4%9F%E8%BD%BD%E5%8F%8A%E6%95%85%E9%9A%9C%E6%A3%80%E6%B5%8B%E8%A3%85%E7%BD%AE/"
           data-tag="线路故障检测,自平衡电桥,正交解调，FPGA"
           data-author="" >
            <span class="post-title" title="【电赛】线路负载及故障检测装置">【电赛】线路负载及故障检测装置</span>
            <span class="post-date" title="2021-03-13 20:43:36">2021/03/13</span>
        </a>
        
        
        <a  class="全部文章 嵌入式和硬件 "
           href="/2021/03/12/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%92%8C%E7%A1%AC%E4%BB%B6/%E3%80%90%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E3%80%91%E5%9F%BA%E4%BA%8EAtlas-200-DK%E7%9A%84%E9%9A%9C%E7%A2%8D%E7%89%A9%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"
           data-tag="Atlas,深度学习,神经网络,障碍物识别,目标识别"
           data-author="" >
            <span class="post-title" title="【本科毕业设计】基于Atlas_200_DK的障碍物识别系统设计与实现">【本科毕业设计】基于Atlas_200_DK的障碍物识别系统设计与实现</span>
            <span class="post-date" title="2021-03-12 19:20:57">2021/03/12</span>
        </a>
        
        
        <a  class="全部文章 软件使用 "
           href="/2021/02/12/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/%E5%B8%B8%E7%94%A8hexo%E5%8D%9A%E5%AE%A2%E6%93%8D%E4%BD%9C/"
           data-tag="hexo指令"
           data-author="" >
            <span class="post-title" title="常用hexo博客操作">常用hexo博客操作</span>
            <span class="post-date" title="2021-02-12 13:14:45">2021/02/12</span>
        </a>
        
        
        <a  class="全部文章 计算机视觉 "
           href="/2021/01/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%8D%AB%E6%98%9F%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1review/"
           data-tag="位姿估计"
           data-author="" >
            <span class="post-title" title="卫星姿态估计综述">卫星姿态估计综述</span>
            <span class="post-date" title="2021-01-16 10:42:41">2021/01/16</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-计算机视觉/位姿估计/姿态估计基础(杨业鹏-20220310203222)" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">位姿估计基础及论文</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            <i class="iconfont icon-category"></i>
            
            
            <a  data-rel="计算机视觉">计算机视觉</a>
            
        </span>
        
        
        <span class="tag">
            <i class="iconfont icon-tag"></i>
            
            <a class="color5">位姿估计</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2023-03-12 15:58:50'>2021-10-20 09:49</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#3D%E6%97%8B%E8%BD%AC%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="toc-text">3D旋转的表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PnP"><span class="toc-text">PnP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AF%E5%88%86%E7%B1%BB%E5%92%8C%E7%A1%AC%E5%88%86%E7%B1%BB"><span class="toc-text">软分类和硬分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BOP-Challenge-2020-on-6D-Object-Localization"><span class="toc-text">BOP Challenge 2020 on 6D Object Localization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CosyPose-Consistent-multi-view-multi-object-6D-pose-estimation"><span class="toc-text">CosyPose: Consistent multi-view multi-object 6D pose estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HybridPose-6D-Object-Pose-Estimation-under-Hybrid-Representations%EF%BC%88CVPR-2020%EF%BC%89"><span class="toc-text">HybridPose: 6D Object Pose Estimation under Hybrid Representations（CVPR 2020）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DPOD-6D-Pose-Object-Detector-and-Refiner"><span class="toc-text">DPOD: 6D Pose Object Detector and Refiner</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CDPN-Coordinates-based-Disentangled-Pose-Network-for-Real-time-RGB-based-6-DoF-Object-Pose-Estimation"><span class="toc-text">CDPN: Coordinates-based Disentangled Pose Network for Real-time RGB-based 6-DoF Object Pose Estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pix2Pose-Pixel-Wise-Coordinate-Regression-of-Objects-for-6D-Pose-Estimation%EF%BC%88ICCV2019%EF%BC%89"><span class="toc-text">Pix2Pose: Pixel-Wise Coordinate Regression of Objects for 6D Pose Estimation（ICCV2019）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Real-Time-Seamless-Single-Shot-6D-Object-Pose-Prediction%EF%BC%88CVPR2018%EF%BC%89"><span class="toc-text">Real-Time Seamless Single Shot 6D Object Pose Prediction（CVPR2018）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SSD-6D-Making-RGB-Based-3D-Detection-and-6D-Pose-Estimation-Great-Again"><span class="toc-text">SSD-6D: Making RGB-Based 3D Detection and 6D Pose Estimation Great Again</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BundleTrack-6D-Pose-Tracking-for-Novel-Objects-without-Instance-or-Category-Level-3D-Models"><span class="toc-text">BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GDR-Net-Geometry-Guided-Direct-Regression-Network-for-Monocular-6D-Object-Pose-Estimation%EF%BC%88CVPR-2021%EF%BC%89%EF%BC%88%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%BF%A1%E6%81%AF%E6%8C%87%E5%AF%BC%E7%9A%84%E5%8D%95%E7%9B%AE6D%E7%89%A9%E4%BD%93%E5%A7%BF%E6%80%81%E7%9B%B4%E6%8E%A5%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%EF%BC%89"><span class="toc-text">GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation（CVPR 2021）（基于几何信息指导的单目6D物体姿态直接回归算法）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#EfficientPose-An-efficient-accurate-and-scalable-end-to-end-6D-multi-object-pose-estimation-approach"><span class="toc-text">EfficientPose: An efficient, accurate and scalable end-to-end 6D multi object pose estimation approach</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DOPE-%E5%9C%A8ros%E4%B8%8A%E8%B7%91%E7%9A%84"><span class="toc-text">DOPE  在ros上跑的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PVNet-Pixel-wise-Voting-Network-for-6DoF-Pose-Estimation"><span class="toc-text">PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF"><span class="toc-text">学习路线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="toc-text">经典特征点检测算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%8D%E5%A7%BF%E7%9A%84%E5%88%9A%E4%BD%93%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%9D%90%E6%A0%87%E7%B3%BB%E8%BD%AC%E6%8D%A2-%E2%80%93-%E6%95%B0%E5%80%BC%E4%B9%8B%E5%88%83-MathSword"><span class="toc-text">位姿的刚体变换与坐标系转换 – 数值之刃 MathSword</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E7%9A%84%E5%8D%95%E7%9B%AERGB%E8%A7%86%E8%A7%89%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95%EF%BC%8C%E6%B2%A1%E6%9C%89%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%90%84%E7%A7%8D%E7%BD%91%E7%BB%9C"><span class="toc-text">经典的单目RGB视觉跟踪算法，没有深度学习各种网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sparse-Representation-for-3D-Shape-Estimation-A-Convex-Relaxation-Approach"><span class="toc-text">Sparse Representation for 3D Shape Estimation: A Convex Relaxation Approach</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MediaPipe"><span class="toc-text">MediaPipe</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E7%BB%84%E4%BC%9A%E2%80%94%E2%80%94%E5%88%9A%E4%BD%936D%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1"><span class="toc-text">大组会——刚体6D位姿估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-text">定义</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ORB-SLAM"><span class="toc-text">ORB-SLAM</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="3D旋转的表示"><a href="#3D旋转的表示" class="headerlink" title="3D旋转的表示"></a>3D旋转的表示</h2><ol>
<li><p>旋转矩阵</p>
</li>
<li><p>欧拉角</p>
<p> 使用动态欧拉角会出现万向锁现象；静态欧拉角不存在万向锁的问题。通时还要注意不同的旋转顺序所得的结果是不同的。</p>
<p> <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Bt4y1v7R1?from=search&amp;seid=2218520216726804689&amp;spm_id_from=333.337.0.0">3d旋转欧拉角与万向锁！Cocos Creator 3D!_哔哩哔哩_bilibili</a></p>
</li>
<li><p>四元数</p>
<p> <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1SW411y7W1/?spm_id_from=autoNext">四元数的可视化_哔哩哔哩_bilibili</a></p>
<p> <a target="_blank" rel="noopener" href="https://eater.net/quaternions/video/intro">Visualizing quaternions | 3blue1brown + Ben Eater</a>交互式体验四元数</p>
<p> <img src="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222" alt="image-20211104112131946">/../姿态估计基础/image-20211104112131946.png)<img src="/姿态估计基础/image-20211104112421258.png" alt="image-20211104112421258"><img src="/姿态估计基础/image-20211104112437943.png" alt="image-20211104112437943"></p>
<p> 四元数就相当于后三个数定义了一个单位向量作为旋转轴，第一个数代表旋转的角度</p>
<p> 设旋转角为θ(从轴的正向箭头处看下去，θ为正则向逆时针旋转，为负则向顺时针旋转)，<strong>q = cos(θ/2) + sin(θ/2)(xi + yj + zk) = q0 + q1i + q2j +q3k</strong></p>
</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lql0716/article/details/72597719">旋转矩阵、欧拉角、四元数理论及其转换关系<em>aibotlab的博客-CSDN博客</em>欧拉角转四元数</a></p>
<h2 id="PnP"><a href="#PnP" class="headerlink" title="PnP"></a>PnP</h2><p>待</p>
<h2 id="软分类和硬分类"><a href="#软分类和硬分类" class="headerlink" title="软分类和硬分类"></a>软分类和硬分类</h2><p>软分类：使用的是概率模型，输出不同类对应的概率，最后的分类结果取概率最大的类，如多SVM组合分类；</p>
<p>硬分类：使用的是非概率模型，分类结果就是决策函数的决策结果；</p>
<h2 id="BOP-Challenge-2020-on-6D-Object-Localization"><a href="#BOP-Challenge-2020-on-6D-Object-Localization" class="headerlink" title="BOP Challenge 2020 on 6D Object Localization"></a>BOP Challenge 2020 on 6D Object Localization</h2><p>In the BOP Challenge 2019, methods using the <strong>depth image channel</strong>, whichwere mostly based on the <strong>point pair features (PPF’s)</strong> [10], clearly outperformed methods relying <strong>only on the RGB channels</strong>, all of which were based on deep neural networks (DNN’s).  （19年及以前PPF方法优于深度学习方法）</p>
<p>20年的比赛中有五个DNN方法超过了19年的冠军(采用PPF)，第三名的方法只使用了RGB通道，完全没用深度通道。</p>
<p><img src="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222" alt="image-20211123085515345">/../姿态估计基础/image-20211123085515345.png)</p>
<p>BOP数据集说明：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u014712806/article/details/112339410">BOP数据集格式说明_屠龙之术-CSDN博客_bop文件</a></p>
<p>PBR全称(Physicallly-Based Rendering)</p>
<h2 id="CosyPose-Consistent-multi-view-multi-object-6D-pose-estimation"><a href="#CosyPose-Consistent-multi-view-multi-object-6D-pose-estimation" class="headerlink" title="CosyPose: Consistent multi-view multi-object 6D pose estimation"></a>CosyPose: Consistent multi-view multi-object 6D pose estimation</h2><p>这个代码没跑出来<a target="_blank" rel="noopener" href="https://github.com/ylabbe/cosypose">ylabbe/cosypose: Code for “CosyPose: Consistent multi-view multi-object 6D pose estimation”, ECCV 2020. (github.com)</a></p>
<h2 id="HybridPose-6D-Object-Pose-Estimation-under-Hybrid-Representations（CVPR-2020）"><a href="#HybridPose-6D-Object-Pose-Estimation-under-Hybrid-Representations（CVPR-2020）" class="headerlink" title="HybridPose: 6D Object Pose Estimation under Hybrid Representations（CVPR 2020）"></a>HybridPose: 6D Object Pose Estimation under Hybrid Representations（<strong>CVPR 2020</strong>）</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/john_bh/article/details/103998704">6D位姿估计 HybridPose: 6D Object Pose Estimation under Hybrid Representations_不忘初心~-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/chensong1995/HybridPose">chensong1995/HybridPose: HybridPose: 6D Object Pose Estimation under Hybrid Representation (CVPR 2020) (github.com)</a>这个star多，正在跑</p>
<p>复现遇到的bug：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_15158911/article/details/107887490">(25条消息) win10安装visual studio C++ build tools 提示安装包丢失或毁坏_与君共勉-CSDN博客_buildtools_msbuild.msi</a></p>
<p><img src="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222" alt="image-20211123112129454">/../姿态估计基础/image-20211123112129454.png)</p>
<h2 id="DPOD-6D-Pose-Object-Detector-and-Refiner"><a href="#DPOD-6D-Pose-Object-Detector-and-Refiner" class="headerlink" title="DPOD: 6D Pose Object Detector and Refiner"></a>DPOD: 6D Pose Object Detector and Refiner</h2><p><img src="/姿态估计基础.assets/Screenshot from 2021-12-05 20-02-59.png" alt="Screenshot from 2021-12-05 20-02-59"></p>
<p>这个bug解决不了，放弃了</p>
<h2 id="CDPN-Coordinates-based-Disentangled-Pose-Network-for-Real-time-RGB-based-6-DoF-Object-Pose-Estimation"><a href="#CDPN-Coordinates-based-Disentangled-Pose-Network-for-Real-time-RGB-based-6-DoF-Object-Pose-Estimation" class="headerlink" title="CDPN: Coordinates-based Disentangled Pose Network for Real-time RGB-based 6-DoF Object Pose Estimation"></a>CDPN: Coordinates-based Disentangled Pose Network for Real-time RGB-based 6-DoF Object Pose Estimation</h2><p><a target="_blank" rel="noopener" href="https://github.com/LZGMatrix/CDPN_ICCV2019_ZhigangLi">https://github.com/LZGMatrix/CDPN_ICCV2019_ZhigangLi</a></p>
<p>正在尝试</p>
<h2 id="Pix2Pose-Pixel-Wise-Coordinate-Regression-of-Objects-for-6D-Pose-Estimation（ICCV2019）"><a href="#Pix2Pose-Pixel-Wise-Coordinate-Regression-of-Objects-for-6D-Pose-Estimation（ICCV2019）" class="headerlink" title="Pix2Pose: Pixel-Wise Coordinate Regression of Objects for 6D Pose Estimation（ICCV2019）"></a>Pix2Pose: Pixel-Wise Coordinate Regression of Objects for 6D Pose Estimation（ICCV2019）</h2><p>由于遮挡和对称性等问题，仅使用<strong>RGB图像</strong>估计物体的6D姿态仍然具有挑战性。如果没有专家知识或专业的扫描设备，也<strong>很难构建具有精确纹理的三维模型</strong>。为了解决这些问题，我们提出了一种新的位姿估计方法Pix2Pose，它可以在没有纹理模型的情况下预测每个目标像素的三维坐标。设计了一种自动编码器结构来估计三维坐标和每个像素的期望误差。然后将这些像素级预测用于多个阶段，形成2D-3D对应关系，用RANSAC迭代的PnP算法直接计算姿态。我们的方法通过利用最近在生成性对抗训练中的成果来精确地恢复被遮挡的部分，从而对遮挡具有鲁棒性。此外，提出了一种新的损耗函数变压器损耗，通过将预测引导到最接近的对称姿态来处理对称目标，对包含对称和遮挡目标的三个不同基准数据集的计算表明，我们的方法优于仅使用RGB图像的最新方法。</p>
<p><img src="/mnt/data/blog/AI/姿态估计基础/image-20220308091537677.png" alt="image-20220308091537677" style="zoom:50%;"></p>
<p>tensorflow  &amp;  训练步骤复杂<a target="_blank" rel="noopener" href="https://github.com/kirumang/Pix2Pose">https://github.com/kirumang/Pix2Pose</a></p>
<h2 id="Real-Time-Seamless-Single-Shot-6D-Object-Pose-Prediction（CVPR2018）"><a href="#Real-Time-Seamless-Single-Shot-6D-Object-Pose-Prediction（CVPR2018）" class="headerlink" title="Real-Time Seamless Single Shot 6D Object Pose Prediction（CVPR2018）"></a>Real-Time Seamless Single Shot 6D Object Pose Prediction（CVPR2018）</h2><p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.08848">https://arxiv.org/abs/1711.08848</a><br>代码链接：<a target="_blank" rel="noopener" href="https://github.com/Microsoft/singleshotpose">https://github.com/Microsoft/singleshotpose</a></p>
<p><strong>主要思想</strong>：我们提出了一种单阶段方法来同时检测RGB图像中的一个物体并预测其6D姿态，不需要多个阶段或检查多个假设。不像最近提出的一些单阶段技术，它只预测一个近似6D的姿势，然后必须细化，我们是足够精确的，不需要额外的后处理。它的速度非常快，在Titan X（帕斯卡）GPU上每秒50帧，因此更适合实时处理。我们的方法的关键部分是一个新的CNN架构，直接预测对象的3D边界框的投影顶点的2D图像位置，然后用PnP算法估计物体的6D姿态。我们的单目标和多目标姿态估计方法在LINEMOD和OCCLUSION数据集上明显优于其他最近基于CNN的方法。</p>
<p>主要贡献： 论文的主要贡献是一个新的网络架构，即一个快速和准确的单阶段6D姿势预测网络，不需要任何后处理。它以无缝和自然的方式扩展了用于二维检测的单阶段CNN结构去执行6D检测任务。实现基于YOLO，但该方法适用于其他单阶段检测器，如SSD及其变体。</p>
<p>代码环境太老了</p>
<p>新版代码  <a target="_blank" rel="noopener" href="https://github.com/a2824256/singleshotpose_imp">https://github.com/a2824256/singleshotpose_imp</a>   （据说自制模型位姿估计异常） </p>
<p>Single Shot 6D Object Pose Prediction代码复现—测试<a target="_blank" rel="noopener" href="https://codeantenna.com/a/nuYk97dWkZ">https://codeantenna.com/a/nuYk97dWkZ</a></p>
<h2 id="SSD-6D-Making-RGB-Based-3D-Detection-and-6D-Pose-Estimation-Great-Again"><a href="#SSD-6D-Making-RGB-Based-3D-Detection-and-6D-Pose-Estimation-Great-Again" class="headerlink" title="SSD-6D: Making RGB-Based 3D Detection and 6D Pose Estimation Great Again"></a>SSD-6D: Making RGB-Based 3D Detection and 6D Pose Estimation Great Again</h2><p>主要思想：提出了一种新的基于RGB数据的三维模型实例检测和6D姿态估计方法。为此，我们扩展了流行的SSD范式，以覆盖完整的6D姿势空间，并仅对合成模型数据进行训练。我们的方法可以与当前最先进的方法在多个具有挑战性的RGBD数据集上竞争或超越。此外，我们的方法在10Hz左右，要比相关的其它方法快很多倍。</p>
<p>主要贡献：</p>
<p>（1） 一个仅利用合成三维模型信息的训练阶段<br>（2） 模型位姿空间的分解，便于对称性的训练和处理<br>（3） SSD的一种扩展，产生2D检测并推断出正确的6D姿势</p>
<p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.10006v1">https://arxiv.org/abs/1711.10006v1</a><br>代码链接：<a target="_blank" rel="noopener" href="https://github.com/wadimkehl/ssd-6d">https://github.com/wadimkehl/ssd-6d</a>    没有提供训练代码</p>
<h2 id="BundleTrack-6D-Pose-Tracking-for-Novel-Objects-without-Instance-or-Category-Level-3D-Models"><a href="#BundleTrack-6D-Pose-Tracking-for-Novel-Objects-without-Instance-or-Category-Level-3D-Models" class="headerlink" title="BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models"></a>BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models</h2><p>rgbd输入</p>
<p><strong>特别之处</strong>：</p>
<ul>
<li>不需要被跟踪物体的3D模型</li>
<li>稳定，不受明显遮挡的影响</li>
<li>10Hz</li>
<li>在NOCS上效果非常好，在YCBInEOAT上效果与se(3)-TrackNet类似（比se差一点）</li>
</ul>
<h2 id="GDR-Net-Geometry-Guided-Direct-Regression-Network-for-Monocular-6D-Object-Pose-Estimation（CVPR-2021）（基于几何信息指导的单目6D物体姿态直接回归算法）"><a href="#GDR-Net-Geometry-Guided-Direct-Regression-Network-for-Monocular-6D-Object-Pose-Estimation（CVPR-2021）（基于几何信息指导的单目6D物体姿态直接回归算法）" class="headerlink" title="GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation（CVPR 2021）（基于几何信息指导的单目6D物体姿态直接回归算法）"></a>GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation（CVPR 2021）（基于几何信息指导的单目6D物体姿态直接回归算法）</h2><h2 id="EfficientPose-An-efficient-accurate-and-scalable-end-to-end-6D-multi-object-pose-estimation-approach"><a href="#EfficientPose-An-efficient-accurate-and-scalable-end-to-end-6D-multi-object-pose-estimation-approach" class="headerlink" title="EfficientPose: An efficient, accurate and scalable end-to-end 6D multi object pose estimation approach"></a>EfficientPose: An efficient, accurate and scalable end-to-end 6D multi object pose estimation approach</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41707788/article/details/120832323">【6D Pose/论文阅读】EfficientPose_遗梦少年的博客-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/rush9838465/article/details/112475562">https://blog.csdn.net/rush9838465/article/details/112475562</a></p>
<p>代码： <a target="_blank" rel="noopener" href="https://github.com/ybkscht/EfficientPose">https://github.com/ybkscht/EfficientPose</a></p>
<p>论文： <a target="_blank" rel="noopener" href="https://click.endnote.com/viewer?doi=10.48550%2Farxiv.2011.04307&amp;token=WzM0NTc1MTMsIjEwLjQ4NTUwL2FyeGl2LjIwMTEuMDQzMDciXQ.TMWGnTMXlvPuSUwFgmZJHcon4Ek">https://click.endnote.com/viewer?doi=10.48550%2Farxiv.2011.04307&amp;token=WzM0NTc1MTMsIjEwLjQ4NTUwL2FyeGl2LjIwMTEuMDQzMDciXQ.TMWGnTMXlvPuSUwFgmZJHcon4Ek</a></p>
<p>测试失败</p>
<h2 id="DOPE-在ros上跑的"><a href="#DOPE-在ros上跑的" class="headerlink" title="DOPE  在ros上跑的"></a>DOPE  在ros上跑的</h2><p><a target="_blank" rel="noopener" href="https://github.com/yehengchen/DOPE-ROS-D435">yehengchen/DOPE-ROS-D435: Object 6DoF Pose Estimation for Assembly Robots Trained on Synthetic Data - ROS Kinetic/Melodic Using Intel® RealSense D435 (github.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/NVlabs/Deep_Object_Pose">NVlabs/Deep_Object_Pose: Deep Object Pose Estimation (DOPE) – ROS inference (CoRL 2018) (github.com)</a></p>
<h2 id="PVNet-Pixel-wise-Voting-Network-for-6DoF-Pose-Estimation"><a href="#PVNet-Pixel-wise-Voting-Network-for-6DoF-Pose-Estimation" class="headerlink" title="PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation"></a>PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation</h2><p><a target="_blank" rel="noopener" href="https://github.com/zju3dv/pvnet">https://github.com/zju3dv/pvnet</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zju3dv/clean-pvnet">https://github.com/zju3dv/clean-pvnet</a></p>
<p>作者还开源了他们用<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=blender&amp;spm=1001.2101.3001.7020">blender</a>合成数据代码：<a target="_blank" rel="noopener" href="https://github.com/zju3dv/pvnet-rendering">https://github.com/zju3dv/pvnet-rendering</a></p>
<p>其他博客：</p>
<p>PVNET代码复现讲解<a target="_blank" rel="noopener" href="https://www.freesion.com/article/85511243426/">https://www.freesion.com/article/85511243426/</a></p>
<p>pvnet——总结<a target="_blank" rel="noopener" href="https://blog.csdn.net/Marilynviolet/article/details/100747094">https://blog.csdn.net/Marilynviolet/article/details/100747094</a></p>
<p><img src="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222" alt="image-20220308170517455">/..//mnt/data/blog/AI/姿态估计基础/image-20220308170517455.png)</p>
<pre><code>ROOT=/home/young/code/clean-pvnet
cd $ROOT/lib/csrc
export CUDA_HOME="/usr/local/cuda-11.5"
cd ransac_voting
python setup.py build_ext --inplace
cd ../nn
python setup.py build_ext --inplace
cd ../fps
python setup.py build_ext --inplace

# If you want to run PVNet with a detector
cd ../dcn_v2
python setup.py build_ext --inplace

# If you want to use the uncertainty-driven PnP
cd ../uncertainty_pnp
sudo apt-get install libgoogle-glog-dev
sudo apt-get install libsuitesparse-dev
sudo apt-get install libatlas-base-dev
python setup.py build_ext --inplace


ROOT=/path/to/clean-pvnet
cd $ROOT/data
ln -s /media/young/young/dataset/LINEMOD/LINEMOD linemod
ln -s /path/to/linemod_orig linemod_orig
ln -s /path/to/occlusion_linemod occlusion_linemod

# the following is used for tless
ln -s /path/to/tless tless
ln -s /path/to/cache cache
ln -s /path/to/SUN2012pascalformat sun
</code></pre><p>安装中遇到cuda版本问题</p>
<pre><code>conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=10.0 -c pytorch
</code></pre><p>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/young/code/pvnet/lib/utils/extend_utils/lib</p>
<pre><code>ln -s /media/young/young/dataset/LINEMOD/LINEMOD $ROOT/data/LINEMOD
</code></pre><p>本文解决了在严重遮挡或截断下从单个 RGB 图像进行 6DoF 姿态估计的挑战。 最近的许多工作表明，一种两阶段方法，首先检测关键点，然后解决用于姿势估计的 Perspective-n-Point (PnP) 问题，取得了显着的性能。 然而，这些方法中的大多数仅通过回归图像坐标或热图来定位一组稀疏关键点，这对遮挡和截断很敏感。 相反，我们引入了逐像素投票网络 (PVNet) 来回归指向关键点的逐像素单位向量，并使用这些向量使用 RANSAC 对关键点位置进行投票。 这为定位被遮挡或截断的关键点创建了灵活的表示。 这种表示的另一个重要特征是它提供了关键点位置的不确定性，PnP 求解器可以进一步利用这些不确定性。 实验表明，所提出的方法在 LINEMOD、Occlusion LINEMOD 和 YCBVideo 数据集上大大优于现有技术，同时对实时姿态估计也很有效。 我们进一步创建了一个截断 LINEMOD 数据集，以验证我们的方法对截断的鲁棒性。 该代码将在 <a target="_blank" rel="noopener" href="https://zju-3dv.github.io/pvnet/">https://zju-3dv.github.io/pvnet/</a> 上提供。</p>
<p>传统方法依赖手工特征，对于图像变化和背景干扰不够鲁棒（why？）</p>
<p>传统网络关键点回归+pnp，有遮挡问题</p>
<p>我们提出了一种使用<strong>像素级投票网络</strong> (PVNet) 进行 6D 姿势估计的新框架。 基本思想如图 1 所示。PVNet 不是直接回归关键点的图像坐标，而是预测表示从对象的每个像素到关键点的方向的单位向量。 然后这些方向根据 RANSAC 对关键点位置进行投票。——关键点的<strong>向量场</strong>表示方法</p>
<p>该思想的动机在于，刚体的特性——即我们看到其一部分就能推断出其他部分的相对方向。</p>
<p>不确定性驱动的pnp</p>
<h2 id="学习路线"><a href="#学习路线" class="headerlink" title="学习路线"></a>学习路线</h2><p>这篇博客的评论区贼强</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/dsoftware/article/details/97955570?spm=1001.2101.3001.6650.9&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-9.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-9.no_search_link"> 刚体6D位姿估计方法综述_dsoftware的博客-CSDN博客_6d位姿估计</a></p>
<p><img src="/姿态估计基础/image-20211125112415235.png" alt="image-20211125112415235" style="zoom:50%;"></p>
<p>纹理特征和几何细节丰富的用对应点的方法、纹理特征和几何细节弱的用基于模板的方法、有遮挡的或者是类别级对象的用基于投票的方法</p>
<p>当有遮挡时，基于模板的方法效果最差</p>
<p>了解物体6Dpose的意义，多种表示李代数欧拉角四元数等，用PnP求解6Dpose的原理等；其次，阅读综述论文，看业界为了求解6D姿态用了哪些方法，传统的以及深度学习的，可以只看摘要和前沿；再次，挑选几篇代表性、前沿、开源的代码，实际复现测试，分析优缺点；最后，结合自身项目，确定输入数据是纯RGB，还是RGB-D，还是Lidar点云，有没有对应的3D模型，对于速度或者精度要求多高，是不是只针对实例级别物体等，选择最接近的某个算法，在其上面改进</p>
<p>有很多基于RGB图像的6D位姿估计方法：</p>
<p>PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation；</p>
<p>Pix2Pose: Pixel-Wise Coordinate Regression of Objects for 6D Pose Estimation；</p>
<p>Implicit 3D Orientation Learning for 6D Object Detection from RGB Images；</p>
<p>EPOS: Estimating 6D Pose of Objects with Symmetries；</p>
<p>DPOD: 6D Pose Object Detector and Refiner；</p>
<p>CDPN: Coordinates-Based Disentangled Pose Network for Real-Time RGB-Based 6-DoF Object Pose Estimation；</p>
<p>Segmentation-driven 6D Object Pose Estimation等等</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yong_qi2015/article/details/117004423?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.pc_relevant_default&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=2">物体6-Dof pose estimation主流方法汇总_3D视觉工坊-CSDN博客</a></p>
<p>Uncertainty-Driven 6D Pose Estimation of Objects and Scenes from a Single RGB Image</p>
<h2 id="经典特征点检测算法"><a href="#经典特征点检测算法" class="headerlink" title="经典特征点检测算法"></a>经典特征点检测算法</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/multhree/p/11296945.html">sift、surf、orb 特征提取及最优特征点匹配 - 闽A2436 - 博客园 (cnblogs.com)</a></p>
<p>如果对计算实时性要求非常高，可选用ORB算法，但基本要保证正对拍摄；如果对实行性要求稍高，可以选择SURF；基本不用SIFT。</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Qb411W7cK?p=4">6.SIFT(尺度不变特征变换)_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/dcrmg/article/details/52601010">Surf算法特征点检测与匹配_牧野的博客-CSDN博客_surf算法</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zizi7/article/details/50379973/">最大稳定极值区域（MSER）检测_zizi7的专栏-CSDN博客_mser算法</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/261966288">图像特征算法(三)——ORB算法简述及Python中ORB特征匹配实践 - 知乎 (zhihu.com)</a></p>
<p>使用传统的方法进行单目相机位姿估计：<a target="_blank" rel="noopener" href="https://github.com/nanfeng-dada/pose_estimation">GitHub - nanfeng-dada/pose_estimation: 单目位姿估计，传统机器视觉，opencv pnp算法</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/74597564"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wangguchangqing/p/8287585.html">SLAM入门之视觉里程计(5)：单应矩阵 - Brook_icv - 博客园 (cnblogs.com)</a></p>
<p><img src="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222" alt="image-20220217110036174">/../姿态估计基础/image-20220217110036174.png)</p>
<p>文博分享：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Awesome-Image-Registration-Organization">Awesome-Image-Registration-Organization · GitHub</a></p>
<p>医学上的应用<a target="_blank" rel="noopener" href="https://github.com/fabio86d/HipHop_2D3Dregistration">https://github.com/fabio86d/HipHop_2D3Dregistration</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/dbdxnuliba/article/details/108215073">高翔博士slam课程深度图像数据除以5000的含义<em>dbdxnuliba的博客-CSDN博客</em>高翔博士slam</a></p>
<p><img src="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222" alt="img">/../姿态估计基础/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RiZHhudWxpYmE=,size_16,color_FFFFFF,t_70.png)</p>
<h3 id="位姿的刚体变换与坐标系转换-–-数值之刃-MathSword"><a href="#位姿的刚体变换与坐标系转换-–-数值之刃-MathSword" class="headerlink" title="位姿的刚体变换与坐标系转换 – 数值之刃 MathSword"></a><a target="_blank" rel="noopener" href="http://www.mathsword.com/rigidtrans_coordinatetrans/">位姿的刚体变换与坐标系转换 – 数值之刃 MathSword</a></h3><h3 id="经典的单目RGB视觉跟踪算法，没有深度学习各种网络"><a href="#经典的单目RGB视觉跟踪算法，没有深度学习各种网络" class="headerlink" title="经典的单目RGB视觉跟踪算法，没有深度学习各种网络"></a>经典的单目RGB视觉跟踪算法，没有深度学习各种网络</h3><p>输入一个包含目标物体的序列帧（offline的视频序列或相机输入视频流），然后还需要一个目标物体的三维模型。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/102024694?utm_source=wechat_timeline">啥是Region-based实时单目RGB三维(刚性)物体跟踪（一） - 知乎 (zhihu.com)</a></p>
<h3 id="Sparse-Representation-for-3D-Shape-Estimation-A-Convex-Relaxation-Approach"><a href="#Sparse-Representation-for-3D-Shape-Estimation-A-Convex-Relaxation-Approach" class="headerlink" title="Sparse Representation for 3D Shape Estimation: A Convex Relaxation Approach"></a>Sparse Representation for 3D Shape Estimation: A Convex Relaxation Approach</h3><p>现有问题：</p>
<p>large number of acquisitions from multiple views are often required in order to obtain a complete 3D model, which is not preferred in some real-time applications; the depth sensors in general cannot work outdoor and have a limited sensing range;</p>
<h2 id="MediaPipe"><a href="#MediaPipe" class="headerlink" title="MediaPipe"></a>MediaPipe</h2><p><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/objectron#model_name">https://google.github.io/mediapipe/solutions/objectron#model_name</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=f-Ibri14KMY&amp;t=231s">https://www.youtube.com/watch?v=f-Ibri14KMY&amp;t=231s</a></p>
<p><img src="/2021/10/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80(%E6%9D%A8%E4%B8%9A%E9%B9%8F-20220310203222" alt="image-20220310162325247">/../姿态估计基础/image-20220310162325247.png)</p>
<h2 id="大组会——刚体6D位姿估计"><a href="#大组会——刚体6D位姿估计" class="headerlink" title="大组会——刚体6D位姿估计"></a>大组会——刚体6D位姿估计</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1fa411c7hc?spm_id_from=333.337.search-card.all.click">基于深度学习的特征匹配与位姿估计+端-云协同的AR技术与平台_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.xzhou.me/">Xiaowei Zhou’s Homepage (xzhou.me)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1C34y1S7ik/">基于深度学习的特征点提取，特征点检测的方法总结_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1bA411E7Y9?p=6">【官方字幕】“3D几何与视觉技术”全球在线研讨会_哔哩哔哩_bilibili</a></p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/dsoftware/article/details/106101681">(21条消息) 物体6D位姿的含义<em>Guoguang Du的博客-CSDN博客</em>物体6d位姿</a></p>
<h2 id="ORB-SLAM"><a href="#ORB-SLAM" class="headerlink" title="ORB-SLAM"></a>ORB-SLAM</h2><p>BA优化存在实时性问题</p>
<p>要实时BA的话，需要提供以下条件：</p>
<ol>
<li>关键帧的关键点匹配</li>
<li>关键帧的数量要尽可能少，避免冗余</li>
<li>关键帧要具有显著的视差和大量的回环匹配</li>
<li>关键帧位姿的初始化以及关键点位置的初始化</li>
<li>A local map in exploration where optimization is focused to achieve scalability.</li>
<li>The ability to perform fast global optimizations (e.g., pose graph) to close loops in real time</li>
</ol>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。 </span>
    </div>
</article>







    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2017-2023 Youngyep
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 562px;
    }
    .nav.fullscreen {
        margin-left: -562px;
    }
    .nav-left {
        width: 140px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 512px;
        }
        .nav.fullscreen {
            margin-left: -512px;
        }
        .nav-left {
            width: 120px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 512px;
            margin-left: -512px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
